{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "290d8cb1-c449-4aa8-bbd7-d60118163356",
   "metadata": {},
   "source": [
    "Name: Holly Kular\\\n",
    "Date: 03-19-2024\\\n",
    "Email: hkular@ucsd.edu\\\n",
    "decode_L1.m\\\n",
    "Description: Script for decoding analysis on layer 1 of probabilistic RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000af540-4a71-4886-8250-9bdfbdfa74f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0210ed5e-58cc-4e61-a61a-8ae298c19094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b585d928-bf9e-46a9-a2ba-d77873aa5bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFY HERE\n",
    "# what conditions were the RNNs trained on?\n",
    "RNN_params = {}\n",
    "RNN_params['prob_split'] = '70_30'\n",
    "RNN_params['afc'] = 2\n",
    "RNN_params['coh'] = 'hi'\n",
    "RNN_params['feedback'] = False\n",
    "RNN_params['thresh'] = [.3,.7]\n",
    "\n",
    "# Decoding params\n",
    "D_params = {}\n",
    "D_params['time_avg'] = False\n",
    "D_params['t_win'] = [200,-1]\n",
    "D_params['n_cvs'] = 5\n",
    "D_params['num_cgs'] = 30\n",
    "D_params['label'] = 'stim' # 'stim' or 'choice'\n",
    "D_params['units'] = 'all' # 'all' or 'exc' or 'inh'\n",
    "D_params['pred'] = 'expected' # 'expected' or 'unexpected', trials had stim 0 or 1 dominant\n",
    "\n",
    "# Timing of task\n",
    "task_info = {}\n",
    "task_info['trials'] = 1000\n",
    "task_info['trial_dur'] = 250  # trial duration (timesteps)\n",
    "task_info['stim_on'] = 80\n",
    "task_info['stim_dur'] = 50\n",
    "# decode opts\n",
    "time_avg = False # do we want to look at average over time window?\n",
    "if time_avg:\n",
    "    t_win = [ 200,-1 ]\n",
    "n_cvs = 5\n",
    "window = 50\n",
    "# store the accuracy\n",
    "acc = np.full( ( n_cvs ), np.nan )\n",
    "\n",
    "# penalties to eval\n",
    "num_cgs = 30\n",
    "Cs = np.logspace( -5,1,num_cgs )\n",
    "\n",
    "# set up the grid\n",
    "param_grid = { 'C': Cs, 'kernel': ['linear'] }\n",
    "\n",
    "# define object - use a SVC that balances class weights (because they are biased, e.g. 70/30)\n",
    "# note that can also specify cv folds here, but I'm doing it by hand below in a loop\n",
    "grid = GridSearchCV( SVC(class_weight = 'balanced'),param_grid,refit=True,verbose=0 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a68920d-f067-4e10-a8f1-158f6f447bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Directory\n",
    "# Load data\n",
    "if sys.platform.startswith('linux'):\n",
    "    data_dir = f\"/mnt/neurocube/local/serenceslab/holly/RNN_Geo/data/rdk_{RNN_params['prob_split']}_{RNN_params['afc']}afc/feedforward_only/{RNN_params['coh']}_coh\"\n",
    "else:\n",
    "    data_dir = f\"/Volumes/serenceslab/holly/RNN_Geo/data/rdk_{RNN_params['prob_split']}_{RNN_params['afc']}afc/feedforward_only/{RNN_params['coh']}_coh\"\n",
    "\n",
    "# Chose the model\n",
    "mat_files = [f for f in os.listdir(data_dir) if f.endswith('.mat')]# Get all the trained models (should be 40 .mat files)\n",
    "model_path = os.path.join(data_dir, mat_files[0]) \n",
    "model = loadmat(model_path) # model.keys()\n",
    "\n",
    "# Change this if we want a different number of trials and different default stim (0 is the one RNN was trained on)\n",
    "if D_params['pred'] == 'expected':\n",
    "    data_file = f\"{data_dir}/Trials{task_info['trials']}_model{model_path[-7:-4]}_0expected.npz\"\n",
    "elif D_params['pred'] == 'unexpected':\n",
    "    data_file = f\"{data_dir}/Trials{task_info['trials']}_model{model_path[-7:-4]}_1unexpected.npz\"\n",
    "data = np.load(data_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb644bd5-8ef5-4d48-9f89-366eef55256b",
   "metadata": {},
   "source": [
    "______________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad544991-3c19-491d-8406-f84100cd15d7",
   "metadata": {},
   "source": [
    "## Next: Compare decode expected vs. unexpected\n",
    "Hypothesis: We can decode expected stimulus better than unexpected because the RNN has acquired the expectation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890a0e2a-d3ca-4a53-9136-c1e09628ff06",
   "metadata": {},
   "source": [
    "### Decode expected stim input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cbee79-c20b-42c8-bce0-55251828c482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode trials: RNN stim presented\n",
    "\n",
    "# get the data from layer 1 decode stim\n",
    "# this is a [trial x time step x unit] matrix\n",
    "data_d = data['fr1']\n",
    "labs = data['labs'].squeeze()\n",
    "\n",
    "# get some info about structure of the data\n",
    "tris = data_d.shape[0]             # number of trials\n",
    "tri_ind = np.arange(0,tris)      # list from 0...tris\n",
    "hold_out = int( tris / n_cvs )   # how many trials to hold out\n",
    "\n",
    "# filter by trial type\n",
    "# TODO make sure expected only has expected and unexpected only has unexpected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa71bb43-ef63-455a-985c-11f09299351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(elements, window_size):\n",
    "  if len(elements) <= window_size:\n",
    "    return elements\n",
    "\n",
    "  windows = []\n",
    "  for i in range(len(elements) - window_size + 1):\n",
    "    windows.append(elements[i:i + window_size])\n",
    "\n",
    "  return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9638e824-67a4-4da0-9aca-c8a13bc7045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = sliding_window([1,2,3,4,5,6,7,8,9],2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a855d1f-2c58-4e06-9cf8-798f988722ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do decoding\n",
    "if time_avg:\n",
    "    data_d = np.mean( data_d[ :,t_win[0]:t_win[1],: ], axis = 1 ) # average over time window   \n",
    "        # Within each cross-validation fold\n",
    "    for i in range(n_cvs):\n",
    "\n",
    "        # trials to hold out as test set on this cv fold\n",
    "        tst_ind = tri_ind[ i*hold_out : (i+1)*hold_out ]\n",
    "\n",
    "        # index into the training data on this cv fold\n",
    "        trn_ind = np.setdiff1d( tri_ind, tst_ind )\n",
    "\n",
    "        # get the training data (X) and the training labels (y)\n",
    "        # note that y is unbalanced unless prob is 50/50\n",
    "        X = data_d[ trn_ind,: ]\n",
    "        y = labs[trn_ind]\n",
    "\n",
    "        # Fit the model on the binary labels\n",
    "        grid.fit( X, y )\n",
    "\n",
    "        # get the test data (X) and the test labels (y)\n",
    "        X_test = data_d[tst_ind, :]\n",
    "        y_test = labs[tst_ind]\n",
    "\n",
    "        # predict!\n",
    "        acc[ i ] = grid.score( X_test,y_test )\n",
    "\n",
    "        # Evaluate accuracy\n",
    "        accuracy = np.mean( acc )\n",
    "        # Print overall results\n",
    "        print(f'CV: {i}, {grid.best_estimator_}')  \n",
    "        \n",
    "else:\n",
    "    \n",
    "    decoding_acc = np.zeros((len(range(task_info['stim_dur']+task_info['stim_on'],task_info['trial_dur'])),))\n",
    "\n",
    "    times = sliding_window(range(task_info['stim_dur']+task_info['stim_on'],task_info['trial_dur']), window)\n",
    "    counter = 0\n",
    "    for t in times:\n",
    "\n",
    "      # Get data slice for the current window avg\n",
    "        data_slice = np.mean( data_d[:,t, :], axis = 1 )\n",
    "\n",
    "        # loop over cvs and do classification\n",
    "        for i in range(n_cvs):\n",
    "\n",
    "            # trials to hold out as test set on this cv fold\n",
    "            tst_ind = tri_ind[ i*hold_out : (i+1)*hold_out ]\n",
    "\n",
    "            # index into the training data on this cv fold\n",
    "            trn_ind = np.setdiff1d( tri_ind, tst_ind )\n",
    "\n",
    "            # get the training data (X) and the training labels (y)\n",
    "            X = data_slice[trn_ind,:]\n",
    "            y = labs[trn_ind]\n",
    "\n",
    "            # fit the model\n",
    "            grid.fit( X,y )\n",
    "\n",
    "            # progress report\n",
    "            #print(f'CV: {i}, {grid.best_estimator_}')\n",
    "\n",
    "            # get the test data (X) and the test labels (y)\n",
    "            X_test = data_slice[tst_ind, :]\n",
    "            y_test = labs[tst_ind]\n",
    "\n",
    "            # predict!\n",
    "            acc[ i ] = grid.score( X_test,y_test )\n",
    "        counter +=1\n",
    "        decoding_acc[counter] = np.mean(acc)        \n",
    "        \n",
    "print(f'done decoding')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bca2c5-131b-4461-a2de-1c3dd6809616",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fb16d3-ef6b-4ea0-ac6d-5d1ec5b248fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plots:\n",
    "    # Plot decoding accuracy over time\n",
    "    plt.figure()\n",
    "    plt.plot(range(task_info['stim_dur']+task_info['stim_on'],task_info['trial_dur']), decoding_acc)\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Decoding Accuracy')\n",
    "    plt.title('Decoding Accuracy Over Time')\n",
    "    plt.axvspan(task_info['stim_on'], task_info['stim_on']+task_info['stim_dur'], color = 'gray', alpha = 0.3)\n",
    "    plt.savefig(f\"{data_dir}/decode_stim_exp.png\")\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f55359-85af-4f6d-babd-67b001f6a32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit logistic function\n",
    "def logistic_func(x, a, b, c, d):\n",
    "    return a / (1 + np.exp(-c * (x - d))) + b\n",
    "\n",
    "popt, _ = curve_fit(logistic_func, range(0, task_info['trial_dur']), decoding_acc[0:])\n",
    "\n",
    "# 'popt' will contain the fitted parameters (a, b, c) of the log function\n",
    "\n",
    "# Optional: Estimate the y-value of the asymptote (assuming based on parameter b)\n",
    "asymptote_y = popt[1]\n",
    "print(\"Estimated y-value of the asymptote:\", asymptote_y)\n",
    "\n",
    "# Optional: Visualization\n",
    "plt.plot(range(0, task_info['trial_dur']), decoding_acc[0:], label='Data')\n",
    "plt.plot(range(0, task_info['trial_dur']), logistic_func(range(0, task_info['trial_dur']), *popt), label=f'y asymptote of logistic {round(asymptote_y, 3)}')\n",
    "plt.axvspan(task_info['stim_on'], task_info['stim_on']+task_info['stim_dur'], color = 'gray', alpha = 0.3)\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Decoding Accuracy')\n",
    "plt.title('Decoding Accuracy Over Time (Logistic Fit)')\n",
    "plt.legend()\n",
    "plt.savefig(f\"{data_dir}/decode_stim_expfit.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4ebb63-422f-4e14-982c-88b33ee04331",
   "metadata": {},
   "source": [
    "### Decode unexpected stim input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff4204d-5967-4836-b692-02b3affce268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode trials: RNN stim presented\n",
    "\n",
    "# get the data from layer 1 decode stim\n",
    "# this is a [trial x time step x unit] matrix\n",
    "data_d = data_unexpected['fr1']\n",
    "labs = data_unexpected['labs'].squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d307e7a9-d31e-411e-a1e9-45febcac7297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do decoding\n",
    "if time_avg:\n",
    "    data_d = np.mean( data_d[ :,t_win[0]:t_win[1],: ], axis = 1 ) # average over time window  \n",
    "        # Within each cross-validation fold\n",
    "    for i in range(n_cvs):\n",
    "\n",
    "        # trials to hold out as test set on this cv fold\n",
    "        tst_ind = tri_ind[ i*hold_out : (i+1)*hold_out ]\n",
    "\n",
    "        # index into the training data on this cv fold\n",
    "        trn_ind = np.setdiff1d( tri_ind, tst_ind )\n",
    "\n",
    "        # get the training data (X) and the training labels (y)\n",
    "        # note that y is unbalanced unless prob is 50/50\n",
    "        X = data_d[ trn_ind,: ]\n",
    "        y = labs[trn_ind]\n",
    "\n",
    "        # Fit the model on the binary labels\n",
    "        grid.fit( X, y )\n",
    "\n",
    "        # get the test data (X) and the test labels (y)\n",
    "        X_test = data_d[tst_ind, :]\n",
    "        y_test = labs[tst_ind]\n",
    "\n",
    "        # predict!\n",
    "        acc[ i ] = grid.score( X_test,y_test )\n",
    "\n",
    "        # Evaluate accuracy\n",
    "        accuracy = np.mean( acc )\n",
    "        # Print overall results\n",
    "        print(f'CV: {i}, {grid.best_estimator_}')  \n",
    "        \n",
    "else:\n",
    "    \n",
    "    total_iterations = task_info['trial_dur'] * n_cvs\n",
    "    decoding_acc = np.zeros((task_info['trial_dur'],))\n",
    "    for t_step in range(task_info['trial_dur']):\n",
    "\n",
    "        data_slice = data_d[:, t_step, :]\n",
    "\n",
    "        # loop over cvs and do classification\n",
    "        for i in range(n_cvs):\n",
    "\n",
    "            # trials to hold out as test set on this cv fold\n",
    "            tst_ind = tri_ind[ i*hold_out : (i+1)*hold_out ]\n",
    "\n",
    "            # index into the training data on this cv fold\n",
    "            trn_ind = np.setdiff1d( tri_ind, tst_ind )\n",
    "\n",
    "            # get the training data (X) and the training labels (y)\n",
    "            X = data_slice[trn_ind,:]\n",
    "            y = labs[trn_ind]\n",
    "\n",
    "            # fit the model\n",
    "            grid.fit( X,y )\n",
    "\n",
    "            # progress report\n",
    "            #print(f'CV: {i}, {grid.best_estimator_}')\n",
    "\n",
    "            # get the test data (X) and the test labels (y)\n",
    "            X_test = data_slice[tst_ind, :]\n",
    "            y_test = labs[tst_ind]\n",
    "\n",
    "            # predict!\n",
    "            acc[ i ] = grid.score( X_test,y_test )\n",
    "            update_progress((t_step * n_cvs) + i + 1, total_iterations)\n",
    "        decoding_acc[t_step] = np.mean(acc)        \n",
    "    plots = True # show decoding acc over time\n",
    "    print('')  # Print a newline after the progress bar    \n",
    "print(f'done decoding')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dda1ad3-b6a0-444b-ba9e-1d2db3cb62aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plots:\n",
    "    # Plot decoding accuracy over time\n",
    "    plt.figure()\n",
    "    plt.plot(range(task_info['trial_dur']), decoding_acc)\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Decoding Accuracy')\n",
    "    plt.title('Decoding Accuracy Over Time')\n",
    "    plt.axvspan(task_info['stim_on'], task_info['stim_on']+task_info['stim_dur'], color = 'gray', alpha = 0.3)\n",
    "    plt.savefig(f\"{data_dir}/decode_stim_unx.png\")\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfa04cd-f63a-4ba2-8ba5-b1cc5361ae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit logistic function\n",
    "popt, _ = curve_fit(logistic_func, range(0, task_info['trial_dur']), decoding_acc[0:])\n",
    "\n",
    "# 'popt' will contain the fitted parameters (a, b, c) of the log function\n",
    "\n",
    "# Optional: Estimate the y-value of the asymptote (assuming based on parameter b)\n",
    "asymptote_y = popt[1]\n",
    "print(\"Estimated y-value of the asymptote:\", asymptote_y)\n",
    "\n",
    "# Optional: Visualization\n",
    "plt.plot(range(0, task_info['trial_dur']), decoding_acc[0:], label='Data')\n",
    "plt.plot(range(0, task_info['trial_dur']), logistic_func(range(0, task_info['trial_dur']), *popt), label=f'y asymptote of logistic {round(asymptote_y, 3)}')\n",
    "plt.axvspan(task_info['stim_on'], task_info['stim_on']+task_info['stim_dur'], color = 'gray', alpha = 0.3)\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Decoding Accuracy')\n",
    "plt.title('Decoding Accuracy Over Time (Logistic Fit)')\n",
    "plt.legend()\n",
    "plt.savefig(f\"{data_dir}/decode_stim_unxfit.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805dd033-976b-4b59-9420-1406725f1ecf",
   "metadata": {},
   "source": [
    "______________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0b8ee7-e77f-4703-be61-9da1f1ca9f8f",
   "metadata": {},
   "source": [
    "______________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d9e220-375e-433d-bf79-41a08aa747d9",
   "metadata": {},
   "source": [
    "### Decode expected stim choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2aa4ae-557e-4067-8a3d-63f01c1ca5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode trials: RNN stim choice\n",
    "\n",
    "# get the data from layer 1 decode choice\n",
    "# this is a [trial x time step x unit] matrix\n",
    "data_d = data_expected['fr1']\n",
    "labs = data_expected['outs'][:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac5ce22-d2a3-4afd-ba9f-1449ec954172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do decoding\n",
    "if time_avg:\n",
    "       \n",
    "        # Within each cross-validation fold\n",
    "    for i in range(n_cvs):\n",
    "\n",
    "        # trials to hold out as test set on this cv fold\n",
    "        tst_ind = tri_ind[ i*hold_out : (i+1)*hold_out ]\n",
    "\n",
    "        # index into the training data on this cv fold\n",
    "        trn_ind = np.setdiff1d( tri_ind, tst_ind )\n",
    "\n",
    "        # get the training data (X) and the training labels (y)\n",
    "        X = data_d[ trn_ind,: ]\n",
    "        y = np.select([labs[trn_ind] >= thresh[1], labs[trn_ind] <= thresh[0]], [0,1], default=0)#np.select([labs[trn_ind] >= thresh], [1], default=0) \n",
    "\n",
    "        # Fit the model on the binary labels\n",
    "        grid.fit( X, y )\n",
    "\n",
    "        # get the test data (X) and the test labels (y)\n",
    "        X_test = data_d[tst_ind, :]\n",
    "        y_test = np.select([labs[tst_ind] >= thresh[1], labs[trn_ind] <= thresh[0]], [0,1], default=0)\n",
    "\n",
    "        # predict!\n",
    "        acc[ i ] = grid.score( X_test,y_test )\n",
    "\n",
    "        # Evaluate accuracy\n",
    "        accuracy = np.mean( acc )\n",
    "        # Print overall results\n",
    "        print(f'CV: {i}, {grid.best_estimator_}')  \n",
    "        \n",
    "else:\n",
    "    \n",
    "    total_iterations = task_info['trial_dur'] * n_cvs\n",
    "    decoding_acc = np.zeros((task_info['trial_dur'],))\n",
    "    for t_step in range(task_info['trial_dur']):\n",
    "\n",
    "        data_slice = data_d[:, t_step, :]\n",
    "\n",
    "        # loop over cvs and do classification\n",
    "        for i in range(n_cvs):\n",
    "\n",
    "            # trials to hold out as test set on this cv fold\n",
    "            tst_ind = tri_ind[ i*hold_out : (i+1)*hold_out ]\n",
    "\n",
    "            # index into the training data on this cv fold\n",
    "            trn_ind = np.setdiff1d( tri_ind, tst_ind )\n",
    "\n",
    "            # get the training data (X) and the training labels (y)\n",
    "            X = data_slice[trn_ind,:]\n",
    "            y = np.select([labs[trn_ind] >= thresh[1], labs[trn_ind] <= thresh[0]], [0,1], default=0)\n",
    "\n",
    "            # fit the model\n",
    "            grid.fit( X,y )\n",
    "\n",
    "            # progress report\n",
    "            #print(f'CV: {i}, {grid.best_estimator_}')\n",
    "\n",
    "            # get the test data (X) and the test labels (y)\n",
    "            X_test = data_slice[tst_ind, :]\n",
    "            y_test = np.select([labs[tst_ind] >= thresh[1], labs[tst_ind] <= thresh[0]], [0,1], default=0)\n",
    "\n",
    "            # predict!\n",
    "            acc[ i ] = grid.score( X_test,y_test )\n",
    "            update_progress((t_step * n_cvs) + i + 1, total_iterations)\n",
    "        decoding_acc[t_step] = np.mean(acc)        \n",
    "    plots = True # show decoding acc over time\n",
    "    print('')  # Print a newline after the progress bar    \n",
    "print(f'done decoding')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345d9f99-d0ef-4bb7-9807-a8a6c0a87446",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plots:\n",
    "    # Plot decoding accuracy over time\n",
    "    plt.figure()\n",
    "    plt.plot(range(task_info['trial_dur']), decoding_acc)\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Decoding Accuracy')\n",
    "    plt.title('Decoding Accuracy Over Time')\n",
    "    plt.axvspan(task_info['stim_on'], task_info['stim_on']+task_info['stim_dur'], color = 'gray', alpha = 0.3)\n",
    "    plt.savefig(f\"{data_dir}/decode_choice_exp.png\")\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a836a9-3f37-48d2-baa6-6241eadb9e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit logistic function\n",
    "popt, _ = curve_fit(logistic_func, range(0, task_info['trial_dur']), decoding_acc[0:])\n",
    "\n",
    "# 'popt' will contain the fitted parameters (a, b, c) of the log function\n",
    "\n",
    "# Optional: Estimate the y-value of the asymptote (assuming based on parameter b)\n",
    "asymptote_y = popt[1]\n",
    "print(\"Estimated y-value of the asymptote:\", asymptote_y)\n",
    "\n",
    "# Optional: Visualization\n",
    "plt.plot(range(0, task_info['trial_dur']), decoding_acc[0:], label='Data')\n",
    "plt.plot(range(0, task_info['trial_dur']), logistic_func(range(0, task_info['trial_dur']), *popt), label=f'y asymptote of logistic {round(asymptote_y, 3)}')\n",
    "plt.axvspan(task_info['stim_on'], task_info['stim_on']+task_info['stim_dur'], color = 'gray', alpha = 0.3)\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Decoding Accuracy')\n",
    "plt.title('Decoding Accuracy Over Time (Logistic Fit)')\n",
    "plt.legend()\n",
    "plt.savefig(f\"{data_dir}/decode_choice_expfit.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd8003b-96de-4bf3-b724-eb63269a9e12",
   "metadata": {},
   "source": [
    "### Decode unexpected stim choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67daf47-b4a7-47cf-b141-6bdd2ff5ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode trials: RNN stim choice\n",
    "\n",
    "# get the data from layer 1 decode choice\n",
    "# this is a [trial x time step x unit] matrix\n",
    "data_d = data_unexpected['fr1']\n",
    "labs = data_unexpected['outs'][:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc506f9f-7048-4a9d-a12b-0181de3073f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do decoding\n",
    "if time_avg:\n",
    "       \n",
    "        # Within each cross-validation fold\n",
    "    for i in range(n_cvs):\n",
    "\n",
    "        # trials to hold out as test set on this cv fold\n",
    "        tst_ind = tri_ind[ i*hold_out : (i+1)*hold_out ]\n",
    "\n",
    "        # index into the training data on this cv fold\n",
    "        trn_ind = np.setdiff1d( tri_ind, tst_ind )\n",
    "\n",
    "        # get the training data (X) and the training labels (y)\n",
    "        X = data_d[ trn_ind,: ]\n",
    "        y = np.select([labs[trn_ind] >= thresh[1], labs[trn_ind] <= thresh[0]], [0,1], default=0)#np.select([labs[trn_ind] >= thresh], [1], default=0) \n",
    "\n",
    "        # Fit the model on the binary labels\n",
    "        grid.fit( X, y )\n",
    "\n",
    "        # get the test data (X) and the test labels (y)\n",
    "        X_test = data_d[tst_ind, :]\n",
    "        y_test = np.select([labs[tst_ind] >= thresh[1], labs[trn_ind] <= thresh[0]], [0,1], default=0)\n",
    "\n",
    "        # predict!\n",
    "        acc[ i ] = grid.score( X_test,y_test )\n",
    "\n",
    "        # Evaluate accuracy\n",
    "        accuracy = np.mean( acc )\n",
    "        # Print overall results\n",
    "        print(f'CV: {i}, {grid.best_estimator_}')  \n",
    "        \n",
    "else:\n",
    "    \n",
    "    total_iterations = task_info['trial_dur'] * n_cvs\n",
    "    decoding_acc = np.zeros((task_info['trial_dur'],))\n",
    "    for t_step in range(task_info['trial_dur']):\n",
    "\n",
    "        data_slice = data_d[:, t_step, :]\n",
    "\n",
    "        # loop over cvs and do classification\n",
    "        for i in range(n_cvs):\n",
    "\n",
    "            # trials to hold out as test set on this cv fold\n",
    "            tst_ind = tri_ind[ i*hold_out : (i+1)*hold_out ]\n",
    "\n",
    "            # index into the training data on this cv fold\n",
    "            trn_ind = np.setdiff1d( tri_ind, tst_ind )\n",
    "\n",
    "            # get the training data (X) and the training labels (y)\n",
    "            X = data_slice[trn_ind,:]\n",
    "            y = np.select([labs[trn_ind] >= thresh[1], labs[trn_ind] <= thresh[0]], [0,1], default=0)\n",
    "\n",
    "            # fit the model\n",
    "            grid.fit( X,y )\n",
    "\n",
    "            # progress report\n",
    "            #print(f'CV: {i}, {grid.best_estimator_}')\n",
    "\n",
    "            # get the test data (X) and the test labels (y)\n",
    "            X_test = data_slice[tst_ind, :]\n",
    "            y_test = np.select([labs[tst_ind] >= thresh[1], labs[tst_ind] <= thresh[0]], [0,1], default=0)\n",
    "\n",
    "            # predict!\n",
    "            acc[ i ] = grid.score( X_test,y_test )\n",
    "            update_progress((t_step * n_cvs) + i + 1, total_iterations)\n",
    "        decoding_acc[t_step] = np.mean(acc)        \n",
    "    plots = True # show decoding acc over time\n",
    "    print('')  # Print a newline after the progress bar    \n",
    "print(f'done decoding')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f4f7e2-bfe7-4486-8904-b5e0791f7d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plots:\n",
    "    # Plot decoding accuracy over time\n",
    "    plt.figure()\n",
    "    plt.plot(range(task_info['trial_dur']), decoding_acc)\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Decoding Accuracy')\n",
    "    plt.title('Decoding Accuracy Over Time')\n",
    "    plt.axvspan(task_info['stim_on'], task_info['stim_on']+task_info['stim_dur'], color = 'gray', alpha = 0.3)\n",
    "    plt.savefig(f\"{data_dir}/decode_choice_unx.png\")\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f41bb8-f8a6-404a-a11d-5addcb8edb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit logistic function\n",
    "popt, _ = curve_fit(logistic_func, range(0, task_info['trial_dur']), decoding_acc[0:])\n",
    "\n",
    "# 'popt' will contain the fitted parameters (a, b, c) of the log function\n",
    "\n",
    "# Optional: Estimate the y-value of the asymptote (assuming based on parameter b)\n",
    "asymptote_y = popt[1]\n",
    "print(\"Estimated y-value of the asymptote:\", asymptote_y)\n",
    "\n",
    "# Optional: Visualization\n",
    "plt.plot(range(0, task_info['trial_dur']), decoding_acc[0:], label='Data')\n",
    "plt.plot(range(0, task_info['trial_dur']), logistic_func(range(0, task_info['trial_dur']), *popt), label=f'y asymptote of logistic {round(asymptote_y, 3)}')\n",
    "plt.axvspan(task_info['stim_on'], task_info['stim_on']+task_info['stim_dur'], color = 'gray', alpha = 0.3)\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Decoding Accuracy')\n",
    "plt.title('Decoding Accuracy Over Time (Logistic Fit)')\n",
    "plt.legend()\n",
    "plt.savefig(f\"{data_dir}/decode_choice_unxfit.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7083e229-ed29-42bb-8e55-3184e458b694",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
