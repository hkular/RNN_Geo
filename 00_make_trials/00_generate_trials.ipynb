{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0198b70-3707-449e-bdf6-ecfdc7d3d71b",
   "metadata": {},
   "source": [
    "Name: Robert Kim\\\n",
    "Date: 06-09-2023\\\n",
    "Email: rkim@salk.edu\\\n",
    "generate_trials.m\\\n",
    "Description: Script to generate trials\\\n",
    "\n",
    "coverted from .m to .pynb by Holly Kular\\\n",
    "date: 02-15-2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cb3d0a8-3df1-4528-97d5-1f58aa828384",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from datetime import datetime\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7118ff8c-545c-4483-871f-ffc3b5731a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load rdk_equal just to see\n",
    "\n",
    "data_dir = f\"/mnt/neurocube/local/serenceslab/holly/RNN_Geo/model/models/rdk_70_30/P_rec_0.2_Taus_4.0_25.0\"\n",
    "mat_files = [f for f in os.listdir(data_dir) if f.endswith('.mat')]\n",
    "\n",
    "# Choose one model as an example\n",
    "model_path = os.path.join(data_dir, mat_files[0])\n",
    "model_new = loadmat(model_path)\n",
    "#print(f'performance: {model['eval_perf_mean']}, loss: {model['eval_loss_mean']}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "010fa666-d47e-4cb4-bd4c-86e5de518c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'x1_0', 'r1_0', 'w1_0', 'x2_0', 'r2_0', 'w2_0', 'x3_0', 'r3_0', 'w3_0', 'w21_0', 'w32_0', 'w12_0', 'w23_0', 'taus_gaus1_0', 'taus_gaus2_0', 'taus_gaus3_0', 'u', 'o', 'w1', 'w2', 'w3', 'w21', 'w32', 'w12', 'w23', 'target', 'w_out', 'N1', 'N2', 'N3', 'exc1', 'inh1', 'exc2', 'inh2', 'exc3', 'inh3', 'w_in', 'b_out', 'som_N', 'losses', 'taus', 'eval_perf_mean', 'eval_loss_mean', 'eval_os', 'eval_labels', 'taus_gaus1', 'taus_gaus2', 'taus_gaus3', 'tr', 'activation'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f13e31ac-7868-4e10-b995-ba9eafcf3b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4885613]], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_new['taus_gaus1_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cee727fb-f130-422f-bbb5-0a149f734aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/neurocube/local/serenceslab/holly/RNN_Geo/model/models/rdk_equal/P_rec_0.2_Taus_4.0_25.0/Task_rdk_equal_N1_200_N2_200_N3_200_Taus_4.0_25.0_Act_sigmoid_2025_04_10_031855.mat'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db89de4a-c316-4a51-92aa-b38035d8c07c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add functions from other notebooks\n",
    "%run fnc_generate_trials.ipynb\n",
    "%run fnc_eval_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7976c144-c21b-46ed-a802-0f5f756f2c36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODIFY HERE\n",
    "# what conditions were the RNNs trained on?\n",
    "prob_split = '70_30' # the probability of stimulus 1 vs all\n",
    "afc = '2' # number of alternatives\n",
    "coh = 'hi' # coherence\n",
    "feedback_lab = 'with_feedback' # with_feedback or feedforward_only\n",
    "feedback = True\n",
    "modelnum = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f1d1c2ef-004a-4c2c-8a0b-5fb51956d998",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Directory\n",
    "afc = 2\n",
    "feedback_lab = 'with_feedback'\n",
    "coh = 'lo'\n",
    "if sys.platform.startswith('linux'):\n",
    "    data_dir = f\"/mnt/neurocube/local/serenceslab/holly/RNN_Geo/data/rdk_70_30_{afc}afc/{feedback_lab}/{coh}_coh\"\n",
    "else:\n",
    "    data_dir = f\"/Volumes/serenceslab/holly/RNN_Geo/data/rdk_70_30_{afc}afc/{feedback_lab}/{coh}_coh\"\n",
    "\n",
    "# Get all the trained models (should be 40 .mat files)\n",
    "mat_files = [f for f in os.listdir(data_dir) if f.endswith('.mat')]\n",
    "\n",
    "# Choose one model as an example\n",
    "model_path = os.path.join(data_dir, mat_files[1])\n",
    "model = loadmat(model_path)\n",
    "#print(f'performance: {model['eval_perf_mean']}, loss: {model['eval_loss_mean']}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4ef727a9-f31e-4dcd-a4ce-67c3915b0a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.1337011e-02],\n",
       "       [ 8.7080592e-01],\n",
       "       [ 2.6934521e+00],\n",
       "       [-2.2021699e+00],\n",
       "       [ 2.3153653e+00],\n",
       "       [ 1.1333811e+00],\n",
       "       [ 8.1446838e-01],\n",
       "       [ 2.7659457e+00],\n",
       "       [-1.2895139e+00],\n",
       "       [-7.4274623e-01],\n",
       "       [ 7.4179035e-01],\n",
       "       [ 6.7797977e-01],\n",
       "       [-2.4175506e+00],\n",
       "       [ 1.1966126e+00],\n",
       "       [ 1.1253735e+00],\n",
       "       [ 3.9505765e+00],\n",
       "       [ 3.6264464e-01],\n",
       "       [ 1.9899932e+00],\n",
       "       [ 5.8503538e-01],\n",
       "       [ 2.5549643e+00],\n",
       "       [ 3.1215426e-01],\n",
       "       [ 1.2093687e+00],\n",
       "       [ 3.9123446e-03],\n",
       "       [ 1.3327222e+00],\n",
       "       [ 2.5354888e+00],\n",
       "       [ 1.7376447e+00],\n",
       "       [-1.3965641e+00],\n",
       "       [-2.1762934e+00],\n",
       "       [ 1.4522603e+00],\n",
       "       [ 9.6865278e-01],\n",
       "       [-3.7381272e+00],\n",
       "       [-3.1250048e-01],\n",
       "       [ 2.7086887e+00],\n",
       "       [ 1.9030249e+00],\n",
       "       [-1.1997948e+00],\n",
       "       [ 2.0986381e+00],\n",
       "       [ 2.3928409e+00],\n",
       "       [ 4.9818686e-01],\n",
       "       [ 8.5872233e-02],\n",
       "       [ 4.1748130e-01],\n",
       "       [ 5.9426758e-03],\n",
       "       [ 1.2422298e+00],\n",
       "       [ 1.7296169e+00],\n",
       "       [-2.7320018e+00],\n",
       "       [ 3.7155145e-01],\n",
       "       [-2.4747705e+00],\n",
       "       [ 3.3722072e+00],\n",
       "       [ 1.4045075e+00],\n",
       "       [ 1.6338528e+00],\n",
       "       [ 3.4961131e+00],\n",
       "       [ 5.2017605e-01],\n",
       "       [ 4.1119680e+00],\n",
       "       [ 6.3847017e-01],\n",
       "       [-2.6530428e+00],\n",
       "       [ 2.0011423e+00],\n",
       "       [ 2.4934797e+00],\n",
       "       [ 1.3216908e+00],\n",
       "       [-6.2140677e-02],\n",
       "       [-2.5281045e+00],\n",
       "       [ 8.0287850e-01],\n",
       "       [ 2.2214599e+00],\n",
       "       [ 1.7760404e+00],\n",
       "       [-1.2273520e+00],\n",
       "       [-2.7173591e-01],\n",
       "       [ 2.0276024e+00],\n",
       "       [ 2.5347004e+00],\n",
       "       [ 7.7220762e-01],\n",
       "       [ 7.8537035e-01],\n",
       "       [ 7.9884684e-01],\n",
       "       [ 1.8331070e+00],\n",
       "       [ 1.5429614e+00],\n",
       "       [ 1.3333976e+00],\n",
       "       [-4.9385581e+00],\n",
       "       [ 3.7219555e+00],\n",
       "       [-1.8132732e+00],\n",
       "       [ 2.9551466e+00],\n",
       "       [ 8.7916261e-01],\n",
       "       [ 1.6984159e+00],\n",
       "       [ 6.3004255e-01],\n",
       "       [ 2.7793105e+00],\n",
       "       [ 3.4694521e+00],\n",
       "       [ 6.4980179e-01],\n",
       "       [ 1.3737984e+00],\n",
       "       [ 1.8297708e+00],\n",
       "       [ 1.6285329e+00],\n",
       "       [-1.5117425e+00],\n",
       "       [-5.2251446e-01],\n",
       "       [ 2.3672345e+00],\n",
       "       [ 1.8109932e+00],\n",
       "       [ 2.8906558e+00],\n",
       "       [-2.2713447e+00],\n",
       "       [ 2.9254022e+00],\n",
       "       [ 1.9105592e+00],\n",
       "       [ 2.8211572e+00],\n",
       "       [-6.5250891e-01],\n",
       "       [-9.5458895e-01],\n",
       "       [-3.0365093e+00],\n",
       "       [ 9.6373719e-01],\n",
       "       [-4.7709382e-01],\n",
       "       [ 2.6977868e+00],\n",
       "       [ 2.0257630e+00],\n",
       "       [ 8.7975228e-01],\n",
       "       [-2.1187606e+00],\n",
       "       [ 2.2936685e+00],\n",
       "       [ 2.7778845e+00],\n",
       "       [-4.3925915e+00],\n",
       "       [ 5.6128335e-01],\n",
       "       [ 2.2057431e+00],\n",
       "       [-4.1761193e+00],\n",
       "       [ 7.9937547e-01],\n",
       "       [ 1.3825670e+00],\n",
       "       [-5.3033459e-01],\n",
       "       [-2.0094216e+00],\n",
       "       [-1.4780504e+00],\n",
       "       [ 3.2623928e+00],\n",
       "       [ 2.3430917e+00],\n",
       "       [-2.6913033e+00],\n",
       "       [ 2.7321279e-01],\n",
       "       [ 3.8018007e+00],\n",
       "       [ 6.7733634e-01],\n",
       "       [ 2.7134936e+00],\n",
       "       [ 7.1333760e-01],\n",
       "       [ 1.4872758e+00],\n",
       "       [ 8.4478980e-01],\n",
       "       [-3.1584415e+00],\n",
       "       [ 9.5670438e-01],\n",
       "       [ 9.3375629e-01],\n",
       "       [ 1.4538193e+00],\n",
       "       [ 1.1169819e+00],\n",
       "       [ 2.5757959e+00],\n",
       "       [-3.7131953e+00],\n",
       "       [ 1.1191411e+00],\n",
       "       [-1.2379225e+00],\n",
       "       [-2.9099097e+00],\n",
       "       [ 2.1691170e+00],\n",
       "       [ 2.2586250e+00],\n",
       "       [ 3.5134301e-01],\n",
       "       [ 1.5299983e+00],\n",
       "       [ 2.8838482e+00],\n",
       "       [ 3.7174070e+00],\n",
       "       [ 1.5944226e+00],\n",
       "       [ 2.9823246e+00],\n",
       "       [ 1.6572849e+00],\n",
       "       [ 6.9098318e-01],\n",
       "       [ 2.0983176e-01],\n",
       "       [ 1.3734745e+00],\n",
       "       [-2.1458557e+00],\n",
       "       [-9.8057944e-01],\n",
       "       [ 1.4030321e-01],\n",
       "       [ 1.4390930e+00],\n",
       "       [-1.5148743e+00],\n",
       "       [ 1.5228197e-01],\n",
       "       [ 1.1144515e+00],\n",
       "       [-3.5265825e+00],\n",
       "       [ 1.3005288e+00],\n",
       "       [ 1.1277294e+00],\n",
       "       [ 2.4735284e+00],\n",
       "       [ 2.1618249e+00],\n",
       "       [ 1.8047560e+00],\n",
       "       [ 2.3473175e+00],\n",
       "       [ 1.8973602e+00],\n",
       "       [ 1.9696108e+00],\n",
       "       [-2.9332864e-01],\n",
       "       [ 9.9835575e-01],\n",
       "       [ 1.0487702e+00],\n",
       "       [ 4.3521208e-01],\n",
       "       [-2.3377435e+00],\n",
       "       [ 4.5832582e+00],\n",
       "       [-2.0892463e+00],\n",
       "       [-5.1388311e-01],\n",
       "       [ 1.3763201e+00],\n",
       "       [ 6.8543726e-01],\n",
       "       [ 1.5376095e+00],\n",
       "       [ 2.0214446e+00],\n",
       "       [ 3.8018541e+00],\n",
       "       [ 3.3917978e+00],\n",
       "       [-2.4227943e+00],\n",
       "       [-2.3381655e+00],\n",
       "       [ 2.2685108e+00],\n",
       "       [ 1.6168889e+00],\n",
       "       [ 2.3542774e+00],\n",
       "       [ 4.3194294e+00],\n",
       "       [ 1.8755554e+00],\n",
       "       [-4.3779583e+00],\n",
       "       [-1.1842381e+00],\n",
       "       [ 2.3009264e+00],\n",
       "       [ 1.3405106e+00],\n",
       "       [ 1.2040455e-01],\n",
       "       [ 1.2071310e+00],\n",
       "       [ 1.7282928e+00],\n",
       "       [ 1.4122895e+00],\n",
       "       [-6.0819826e+00],\n",
       "       [ 1.4602873e+00],\n",
       "       [-3.5876777e+00],\n",
       "       [ 1.1912044e+00],\n",
       "       [-7.3468781e-01],\n",
       "       [-3.2793498e+00],\n",
       "       [ 2.3558552e+00],\n",
       "       [ 1.1577824e+00],\n",
       "       [ 2.4875723e-01]], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['taus_gaus1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e806835c-613d-44aa-9f41-ac8d9b1d35ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ** Testing task condition \n",
    "task_info = {}\n",
    "task_info['trials'] = 1000\n",
    "task_info['trial_dur'] = 250  # trial duration (timesteps)\n",
    "task_info['stim_on'] = 80\n",
    "task_info['stim_dur'] = 50\n",
    "task_info['num_stims'] = int(afc) # nAFC\n",
    "if coh == 'hi': # hi_coh = 0.7 vs. lo_coh = 0.6\n",
    "    task_info['coh'] = 0.7 \n",
    "else:\n",
    "    task_info['coh'] = 0.6 \n",
    "    \n",
    "task_info['units'] = 200 # number of units\n",
    "# NOTE: adjust pred and primary_prob to change the testing environement\n",
    "# Ex. Evenly distributed 6-AFC => task_info.primary_prob = 1/6;\n",
    "# Ex. pred=5 and primary_prob = 0.7 => stim \"5\" will be predominant (70% of the time)\n",
    "task_info['pred'] = 0 # predominant stimulus is \"1\"\n",
    "task_info['primary_prob'] = 1/int(afc)#.7 # 1/int(afc) if balanced; # 70-30 split\n",
    "\n",
    "add_noise = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21389ae2-6159-4f55-bbc8-a25136a6beb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Store firing rates, outputs, and labels for each trials\n",
    "fr1 = np.zeros((task_info['trials'], task_info['trial_dur'], task_info['units']))\n",
    "fr2 = np.zeros((task_info['trials'], task_info['trial_dur'], task_info['units']))\n",
    "fr3 = np.zeros((task_info['trials'], task_info['trial_dur'], task_info['units']))\n",
    "outs = np.zeros((task_info['trials'], task_info['trial_dur']))\n",
    "labs = np.zeros((task_info['trials'], 1))\n",
    "\n",
    "for tri in range(0, task_info['trials']):\n",
    "    # Generate trials\n",
    "    u, lab = fnc_generate_trials('rdk', task_info)\n",
    "    # add gauss noise to u\n",
    "    if add_noise:\n",
    "        u_noise = u + np.random.randn(*u.shape)\n",
    "\n",
    "    # Now test the trained model\n",
    "    out, O = fnc_eval_model(model_path, u, feedback)\n",
    "\n",
    "    outs[tri, :] = out['O']  # Store the output signal\n",
    "    labs[tri] = lab\n",
    "    \n",
    "    fr1[tri, :, :] = out['R1']\n",
    "    fr2[tri, :, :] = out['R2']\n",
    "    fr3[tri, :, :] = out['R3']\n",
    "print(f'done generating trials')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e870003-f06a-417b-8ea9-fb5e46fb8ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,5))\n",
    "plt.plot(np.mean(u, axis = 0))\n",
    "plt.xlabel('Time Steps', fontsize = 18)\n",
    "plt.ylabel('Input (au)', fontsize = 18)\n",
    "plt.xticks(fontsize = 14)\n",
    "plt.yticks(fontsize = 14)\n",
    "plt.ylim(-3,3)\n",
    "plt.title('Input Signal Single Trial', fontsize = 18)\n",
    "#fig.savefig('Example_Input_noise.png', dpi=300, bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f3d30b-1e4e-484f-b3ba-a99a0e2df6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = labs == 0\n",
    "fig = plt.figure(figsize=(7,5))\n",
    "first_else_encountered = False \n",
    "for i in range(100):\n",
    "    if idx[i]:\n",
    "        plt.plot(outs[i, :], 'b')\n",
    "    else:\n",
    "        plt.plot(outs[i, :], 'r', label = '_nolegend_' )\n",
    "\n",
    "        \n",
    "plt.xlabel('Time Steps', fontsize = 18)\n",
    "plt.ylabel('Output (au)', fontsize = 18)\n",
    "plt.title('Output Signals from 100 Trials', fontsize = 18)\n",
    "plt.xticks(fontsize = 14)\n",
    "plt.yticks(fontsize = 14)\n",
    "#fig.savefig('Example_Output.png', dpi=300, bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec6874e-4b69-4fb5-9fa8-f6dc484cacb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trial data to load into other notebooks\n",
    "full_file = os.path.join(data_dir, f\"Trials{task_info['trials']}_model{model_path[-7:-4]}_balanced_neutral.npz\")\n",
    "np.savez(full_file,fr1 = fr1, fr2 = fr2, fr3=fr3, outs=outs, labs=labs)\n",
    "print(f'done saving')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcc55a6-2fc6-447a-8f55-f537569c82a0",
   "metadata": {},
   "source": [
    "## -----------------------Exploratory section below-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e704ca-2ae8-4b5d-b8a7-7c08b2cd42cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# decoding over time - done\n",
    "# plot weights - done?\n",
    "# compare inhibitory and excitatory units - in progress\n",
    "# decoding over time - done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35162c4f-43a5-451f-a44b-d1b1c786eb54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Look at model output\n",
    "plt.figure()\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Output (au)')\n",
    "plt.title('RNN Output')\n",
    "plt.plot(out['O'])\n",
    "plt.show()\n",
    "\n",
    "# Look at trials\n",
    "idx = labs == 1\n",
    "plt.figure()\n",
    "first_else_encountered = False \n",
    "for i in range(100):\n",
    "    if idx[i]:\n",
    "        plt.plot(outs[i, :], 'b')\n",
    "    else:\n",
    "        #plt.plot(outs[i, :], 'r', label='Stim 1' if i < 1 else '_nolegend_')\n",
    "        if not first_else_encountered:\n",
    "            plt.plot(outs[i, :], 'r', label='Stim 1')\n",
    "            first_else_encountered = True  # Update flag\n",
    "        else:\n",
    "            plt.plot(outs[i, :], 'r', label='_nolegend_')\n",
    "        \n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Output (au)')\n",
    "plt.title('Output Signals from 100 Trials')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5dded0-e142-42d0-8139-8a051e1754d8",
   "metadata": {},
   "source": [
    "###### outs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce714ad-d639-4421-a4eb-247b68709317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_classification  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122cf5d2-f6e3-4190-bb4a-b1ac454e3d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode trials\n",
    "# which layer do we want? \n",
    "layer = 1\n",
    "\n",
    "# averge fr over this time window post stimulus\n",
    "# this is unit of model time-steps\n",
    "t_win = [ 200,-1 ]\n",
    "\n",
    "# number of cv folds\n",
    "n_cvs = 5 # performance goes up with fewer cvs? looked at 3\n",
    "\n",
    "# store the accuracy\n",
    "acc = np.full( ( n_cvs ), np.nan )\n",
    "\n",
    "# penalties to eval\n",
    "num_cgs = 30\n",
    "Cs = np.logspace( -5,1,num_cgs )\n",
    "\n",
    "# set up the grid\n",
    "param_grid = { 'C': Cs, 'kernel': ['linear'] }\n",
    "\n",
    "# define object - use a SVC that balances class weights (because they are biased, e.g. 70/30)\n",
    "# note that can also specify cv folds here, but I'm doing it by hand below in a loop\n",
    "grid = GridSearchCV( SVC(class_weight = 'balanced'),param_grid,refit=True,verbose=0 )\n",
    "\n",
    "# get the data from the layer that we want\n",
    "# this is a [trial x time step x unit] matrix\n",
    "data_d = locals()[f'fr{layer}']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b1e7ec-3cef-48f3-95f2-01131c62b01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg over time window\n",
    "#data_d = np.mean( data_d[ :,t_win[0]:t_win[1],: ], axis = 1 )\n",
    "\n",
    "# get some info about structure of the data\n",
    "tris = data_d.shape[0]             # number of trials\n",
    "tri_ind = np.arange(0,tris)      # list from 0...tris\n",
    "hold_out = int( tris / n_cvs )   # how many trials to hold out\n",
    "\n",
    "decoding_acc = np.zeros((task_info['trial_dur'],))\n",
    "\n",
    "for t_step in range(task_info['trial_dur']):\n",
    "    \n",
    "    data_slice = data_d[:, t_step, :]\n",
    "    \n",
    "    # loop over cvs and do classification\n",
    "    for i in range(n_cvs):\n",
    "\n",
    "        # trials to hold out as test set on this cv fold\n",
    "        tst_ind = tri_ind[ i*hold_out : (i+1)*hold_out ]\n",
    "\n",
    "        # index into the training data on this cv fold\n",
    "        trn_ind = np.setdiff1d( tri_ind, tst_ind )\n",
    "\n",
    "        # get the training data (X) and the training labels (y)\n",
    "        # note that y is unbalanced unless prob is 50/50\n",
    "        # todo: verify that SVC(class_weight = 'balanced')\n",
    "        # is working as desired!\n",
    "        # HK done: follows formula of n/ki\n",
    "        X = data_slice[trn_ind,:]\n",
    "        y = labs[trn_ind].flatten()\n",
    "\n",
    "        # fit the model\n",
    "        grid.fit( X,y )\n",
    "\n",
    "        # progress report\n",
    "        #print(f'CV: {i}, {grid.best_estimator_}')\n",
    "\n",
    "        # get the test data (X) and the test labels (y)\n",
    "        X_test = data_slice[tst_ind, :]\n",
    "        y_test = labs[tst_ind]\n",
    "\n",
    "        # predict!\n",
    "        acc[ i ] = grid.score( X_test,y_test )\n",
    "\n",
    "    decoding_acc[t_step] = np.mean(acc)\n",
    "print(f'done decoding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a32654-2a0f-43b3-9f4c-ea8758a45340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot decoding accuracy over time\n",
    "plt.figure()\n",
    "plt.plot(range(task_info['trial_dur']), decoding_acc)\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Decoding Accuracy')\n",
    "plt.title('Decoding Accuracy Over Time')\n",
    "plt.axvspan(task_info['stim_on'], task_info['stim_on']+task_info['stim_dur'], color = 'gray', alpha = 0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0e4e67-43df-4b51-9e7f-96cc25c47d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at what is inside the data file\n",
    "data = loadmat(model_path)\n",
    "data.keys() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edb52b9-1118-47db-8aee-8c24dfd1fb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['eval_labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ea4f71-4174-4057-a258-85cf54f7d28d",
   "metadata": {},
   "source": [
    "data['exc1'] # (200,1) 1s and 0s index of which units in layer 1 are excitatory? so multiply that with FR1 to get FR of excitatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc04d689-1e69-4b9c-b81a-7b6d5535329b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming data['w1'], data['w2'], and data['w3'] contain the weights arrays for the three layers\n",
    "weights_layer1 = data['w1']\n",
    "weights_layer2 = data['w2']\n",
    "weights_layer3 = data['w3']\n",
    "\n",
    "# Determine the overall min and max values of the weights arrays\n",
    "min_val = min(weights_layer1.min(), weights_layer2.min(), weights_layer3.min())\n",
    "max_val = max(weights_layer1.max(), weights_layer2.max(), weights_layer3.max())\n",
    "\n",
    "# Create subplots for each layer\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Plot heatmap for layer 1\n",
    "axes[0].imshow(weights_layer1, cmap='viridis', interpolation='nearest')\n",
    "axes[0].set_title('Layer 1 Weights')\n",
    "axes[0].set_xlabel('Unit Index')\n",
    "axes[0].set_ylabel('Unit Index')\n",
    "axes[0].set_aspect('equal')  # Set aspect ratio to be equal\n",
    "\n",
    "# Plot heatmap for layer 2\n",
    "axes[1].imshow(weights_layer2, cmap='viridis', interpolation='nearest')\n",
    "axes[1].set_title('Layer 2 Weights')\n",
    "axes[1].set_xlabel('Unit Index')\n",
    "axes[1].set_ylabel('Unit Index')\n",
    "axes[1].set_aspect('equal')  # Set aspect ratio to be equal\n",
    "\n",
    "# Plot heatmap for layer 3\n",
    "heatmap3 = axes[2].imshow(weights_layer3, cmap='viridis', interpolation='nearest', vmin=min_val, vmax=max_val)\n",
    "axes[2].imshow(weights_layer3, cmap='viridis', interpolation='nearest')\n",
    "axes[2].set_title('Layer 3 Weights')\n",
    "axes[2].set_xlabel('Unit Index')\n",
    "axes[2].set_ylabel('Unit Index')\n",
    "axes[2].set_aspect('equal')  # Set aspect ratio to be equal\n",
    "\n",
    "# Add colorbars\n",
    "fig.colorbar(heatmap3, ax=axes.ravel().tolist(), label='Weight Value')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ecb4d7-f81c-44c2-af2a-a19e45aa5d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming data['w21'] and data['w32'] contain the weights arrays for the recurrent connections\n",
    "weights_layer21 = data['w21']\n",
    "weights_layer32 = data['w32']\n",
    "\n",
    "# Determine the overall min and max values of the weights arrays\n",
    "min_val = min(weights_layer1.min(), weights_layer2.min(), weights_layer3.min())\n",
    "max_val = max(weights_layer1.max(), weights_layer2.max(), weights_layer3.max())\n",
    "\n",
    "# Create subplots for each layer\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot heatmap for layer 1\n",
    "axes[0].imshow(weights_layer21, cmap='viridis', interpolation='nearest')\n",
    "axes[0].set_title('Layer 2 to 1 Weights')\n",
    "axes[0].set_xlabel('Unit Index')\n",
    "axes[0].set_ylabel('Unit Index')\n",
    "axes[0].set_aspect('equal')  # Set aspect ratio to be equal\n",
    "\n",
    "# Plot heatmap for layer 2\n",
    "heatmap2 = axes[1].imshow(weights_layer32, cmap='viridis', interpolation='nearest', vmin=min_val, vmax=max_val)\n",
    "axes[1].imshow(weights_layer32, cmap='viridis', interpolation='nearest')\n",
    "axes[1].set_title('Layer 3 to 2 Weights')\n",
    "axes[1].set_xlabel('Unit Index')\n",
    "axes[1].set_ylabel('Unit Index')\n",
    "axes[1].set_aspect('equal')  # Set aspect ratio to be equal\n",
    "\n",
    "\n",
    "# Add colorbars\n",
    "fig.colorbar(heatmap2, ax=axes.ravel().tolist(), label='Weight Value')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4138710f-022e-42cf-bcf8-8661bd996d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at weights excitatory versus inhibitory units\n",
    "# For now just looking at layer 1 - don't know if it makes sense to combine across layers\n",
    "# Assuming data['w1'], data['w2'], and data['w3'] contain the weights arrays for the three layers\n",
    "Eweights_layer1 = data['w1'] * data['exc1']\n",
    "Iweights_layer1 = data['w1'] * data['inh1']\n",
    "\n",
    "# Determine the overall min and max values of the weights arrays\n",
    "min_val = min(Eweights_layer1.min(), Iweights_layer1.min())\n",
    "max_val = max(Eweights_layer1.max(), Iweights_layer1.max())\n",
    "\n",
    "# Create subplots for each layer\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot heatmap for layer 1\n",
    "axes[0].imshow(Eweights_layer1, cmap='viridis', interpolation='nearest')\n",
    "axes[0].set_title('Layer 1 Excitatory Weights')\n",
    "axes[0].set_xlabel('Unit Index')\n",
    "axes[0].set_ylabel('Unit Index')\n",
    "axes[0].set_aspect('equal')  # Set aspect ratio to be equal\n",
    "\n",
    "# Plot heatmap for layer 2\n",
    "heatmap = axes[1].imshow(Iweights_layer1, cmap='viridis', interpolation='nearest', vmin=min_val, vmax=max_val)\n",
    "axes[1].imshow(Iweights_layer1, cmap='viridis', interpolation='nearest')\n",
    "axes[1].set_title('Layer 1 Inhibitory Weights')\n",
    "axes[1].set_xlabel('Unit Index')\n",
    "axes[1].set_ylabel('Unit Index')\n",
    "axes[1].set_aspect('equal')  # Set aspect ratio to be equal\n",
    "\n",
    "\n",
    "# Add colorbars\n",
    "fig.colorbar(heatmap, ax=axes.ravel().tolist(), label='Weight Value')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c9164b-cf5a-4b51-914d-d04f00a88eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at decoding excitatory versus inhibitory units - in progress\n",
    "# Decode trials\n",
    "# which layer do we want? \n",
    "layer = 1\n",
    "\n",
    "# averge fr over this time window post stimulus\n",
    "# this is unit of model time-steps\n",
    "t_win = [ 200,-1 ]\n",
    "\n",
    "# number of cv folds\n",
    "n_cvs = 5 # performance goes up with fewer cvs? looked at 3\n",
    "\n",
    "# store the accuracy\n",
    "acc = np.full( ( n_cvs ), np.nan )\n",
    "\n",
    "# penalties to eval\n",
    "num_cgs = 30\n",
    "Cs = np.logspace( -5,1,num_cgs )\n",
    "\n",
    "# set up the grid\n",
    "param_grid = { 'C': Cs, 'kernel': ['linear'] }\n",
    "\n",
    "# define object - use a SVC that balances class weights (because they are biased, e.g. 70/30)\n",
    "# note that can also specify cv folds here, but I'm doing it by hand below in a loop\n",
    "grid = GridSearchCV( SVC(class_weight = 'balanced'),param_grid,refit=True,verbose=0 )\n",
    "\n",
    "# get the data from the layer that we want\n",
    "# this is a [trial x time step x unit] matrix\n",
    "data_d = locals()[f'fr{layer}']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d329d7-3c8a-4543-97ae-78156b0ea9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg over time window - in progress\n",
    "#data_d = np.mean( data_d[ :,t_win[0]:t_win[1],: ], axis = 1 )\n",
    "\n",
    "# get some info about structure of the data\n",
    "tris = data_d.shape[0]             # number of trials\n",
    "tri_ind = np.arange(0,tris)      # list from 0...tris\n",
    "hold_out = int( tris / n_cvs )   # how many trials to hold out\n",
    "\n",
    "decoding_acc = np.zeros((task_info['trial_dur'],))\n",
    "\n",
    "for t_step in range(task_info['trial_dur']):\n",
    "    \n",
    "    data_slice = data_d[:, t_step, :]\n",
    "    \n",
    "    # loop over cvs and do classification\n",
    "    for i in range(n_cvs):\n",
    "\n",
    "        # trials to hold out as test set on this cv fold\n",
    "        tst_ind = tri_ind[ i*hold_out : (i+1)*hold_out ]\n",
    "\n",
    "        # index into the training data on this cv fold\n",
    "        trn_ind = np.setdiff1d( tri_ind, tst_ind )\n",
    "\n",
    "        # get the training data (X) and the training labels (y)\n",
    "        # note that y is unbalanced unless prob is 50/50\n",
    "        # todo: verify that SVC(class_weight = 'balanced')\n",
    "        # is working as desired!\n",
    "        # HK done: follows formula of n/ki\n",
    "        X = data_slice[trn_ind,:]\n",
    "        y = labs[trn_ind].flatten()\n",
    "\n",
    "        # fit the model\n",
    "        grid.fit( X,y )\n",
    "\n",
    "        # progress report\n",
    "        #print(f'CV: {i}, {grid.best_estimator_}')\n",
    "\n",
    "        # get the test data (X) and the test labels (y)\n",
    "        X_test = data_slice[tst_ind, :]\n",
    "        y_test = labs[tst_ind]\n",
    "\n",
    "        # predict!\n",
    "        acc[ i ] = grid.score( X_test,y_test )\n",
    "\n",
    "    decoding_acc[t_step] = np.mean(acc)\n",
    "print(f'done decoding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b341eb4-2434-4818-aa7b-acb7b56a1f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot decoding accuracy over time - in progress\n",
    "plt.figure()\n",
    "plt.plot(range(task_info['trial_dur']), decoding_acc)\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Decoding Accuracy')\n",
    "plt.title('Decoding Accuracy Over Time')\n",
    "plt.axvspan(task_info['stim_on'], task_info['stim_on']+task_info['stim_dur'], color = 'gray', alpha = 0.3)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
