{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "290d8cb1-c449-4aa8-bbd7-d60118163356",
   "metadata": {},
   "source": [
    "Name: Holly Kular\\\n",
    "Date: 03-19-2024\\\n",
    "Email: hkular@ucsd.edu\\\n",
    "decode_L1.m\\\n",
    "Description: Script for decoding analysis on layer 1 of probabilistic RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "000af540-4a71-4886-8250-9bdfbdfa74f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0210ed5e-58cc-4e61-a61a-8ae298c19094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_classification  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b585d928-bf9e-46a9-a2ba-d77873aa5bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFY HERE\n",
    "# what conditions were the RNNs trained on?\n",
    "prob_split = '70_30' # the probability of stimulus 1 vs all\n",
    "afc = '6' # number of alternatives\n",
    "coh = 'lo' # coherence\n",
    "feedback = False # interlayer feedback (true or false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a68920d-f067-4e10-a8f1-158f6f447bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Directory\n",
    "if sys.platform.startswith('linux'):\n",
    "    data_dir = f\"/mnt/neurocube/local/serenceslab/holly/RNN_Geo/data/rdk_{prob_split}_{afc}afc/feedforward_only/{coh}_coh\"\n",
    "else:\n",
    "    data_dir = f\"/Volumes/serenceslab/holly/RNN_Geo/data/rdk_{prob_split}_{afc}afc/feedforward_only/{coh}_coh\"\n",
    "\n",
    "# Load data\n",
    "data = np.load(f\"{data_dir}/Trials.npz\")\n",
    "data_expected = np.load(f\"{data_dir}/Trials_0expected.npz\")\n",
    "data_unexpected = np.load(f\"{data_dir}/Trials_1expected.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "79b80693-7dbc-403f-839d-20af277a00fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['fr1'] data['outs'] data['labs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb644bd5-8ef5-4d48-9f89-366eef55256b",
   "metadata": {},
   "source": [
    "______________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad544991-3c19-491d-8406-f84100cd15d7",
   "metadata": {},
   "source": [
    "## Next: Compare decode expected vs. unexpected\n",
    "Hypothesis: We can decode expected stimulus better than unexpected because the RNN has acquired the expectation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890a0e2a-d3ca-4a53-9136-c1e09628ff06",
   "metadata": {},
   "source": [
    "### Decode expected stim input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15cbee79-c20b-42c8-bce0-55251828c482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode trials: RNN stim presented\n",
    "\n",
    "# averge over this time window post stimulus\n",
    "# this is unit of model time-steps\n",
    "t_win = [ 200,-1 ]\n",
    "\n",
    "# number of cv folds\n",
    "n_cvs = 5\n",
    "\n",
    "# store the accuracy\n",
    "acc = np.full( ( n_cvs ), np.nan )\n",
    "\n",
    "# penalties to eval\n",
    "num_cgs = 30\n",
    "Cs = np.logspace( -5,1,num_cgs )\n",
    "\n",
    "# set up the grid\n",
    "param_grid = { 'C': Cs, 'kernel': ['linear'] }\n",
    "\n",
    "# define object - use a SVC that balances class weights (because they are biased, e.g. 70/30)\n",
    "# note that can also specify cv folds here, but I'm doing it by hand below in a loop\n",
    "grid = GridSearchCV( SVC(class_weight = 'balanced'),param_grid,refit=True,verbose=0 )\n",
    "\n",
    "# get the data from layer 1 decode stim\n",
    "# this is a [trial x time step x unit] matrix\n",
    "data_d = data_expected['fr1']\n",
    "labs = data_expected['labs'].squeeze()\n",
    "labs = np.where(labs == 0, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a855d1f-2c58-4e06-9cf8-798f988722ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV: 0, SVC(C=6.2101694189156165, class_weight='balanced', kernel='linear')\n",
      "CV: 1, SVC(C=3.856620421163472, class_weight='balanced', kernel='linear')\n",
      "CV: 2, SVC(C=1.610262027560939e-05, class_weight='balanced', kernel='linear')\n",
      "CV: 3, SVC(C=4.1753189365604006e-05, class_weight='balanced', kernel='linear')\n",
      "CV: 4, SVC(C=10.0, class_weight='balanced', kernel='linear')\n",
      "0.7399999999999999\n"
     ]
    }
   ],
   "source": [
    "# avg over time window\n",
    "data_d = np.mean( data_d[ :,t_win[0]:t_win[1],: ], axis = 1 )\n",
    "\n",
    "# get some info about structure of the data\n",
    "tris = data_d.shape[0]             # number of trials\n",
    "tri_ind = np.arange(0,tris)      # list from 0...tris\n",
    "hold_out = int( tris / n_cvs )   # how many trials to hold out\n",
    "\n",
    "# loop over cvs and do classification\n",
    "for i in range(n_cvs):\n",
    "\n",
    "    # trials to hold out as test set on this cv fold\n",
    "    tst_ind = tri_ind[ i*hold_out : (i+1)*hold_out ]\n",
    "    \n",
    "    # index into the training data on this cv fold\n",
    "    trn_ind = np.setdiff1d( tri_ind, tst_ind )\n",
    "\n",
    "    # get the training data (X) and the training labels (y)\n",
    "    X = data_d[trn_ind,:]\n",
    "    y = labs[trn_ind]\n",
    "\n",
    "    # fit the model\n",
    "    grid.fit( X,y )\n",
    "\n",
    "    # progress report\n",
    "    print(f'CV: {i}, {grid.best_estimator_}')\n",
    "\n",
    "    # get the test data (X) and the test labels (y)\n",
    "    X_test = data_d[tst_ind, :]\n",
    "    y_test = labs[tst_ind]\n",
    "\n",
    "    # predict!\n",
    "    acc[ i ] = grid.score( X_test,y_test )\n",
    "        \n",
    "\n",
    "print( np.mean( acc ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4ebb63-422f-4e14-982c-88b33ee04331",
   "metadata": {},
   "source": [
    "### Decode unexpected stim input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ff4204d-5967-4836-b692-02b3affce268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode trials: RNN stim presented\n",
    "\n",
    "# averge over this time window post stimulus\n",
    "# this is unit of model time-steps\n",
    "t_win = [ 200,-1 ]\n",
    "\n",
    "# number of cv folds\n",
    "n_cvs = 5\n",
    "\n",
    "# store the accuracy\n",
    "acc = np.full( ( n_cvs ), np.nan )\n",
    "\n",
    "# penalties to eval\n",
    "num_cgs = 30\n",
    "Cs = np.logspace( -5,1,num_cgs )\n",
    "\n",
    "# set up the grid\n",
    "param_grid = { 'C': Cs, 'kernel': ['linear'] }\n",
    "\n",
    "# define object - use a SVC that balances class weights (because they are biased, e.g. 70/30)\n",
    "# note that can also specify cv folds here, but I'm doing it by hand below in a loop\n",
    "grid = GridSearchCV( SVC(class_weight = 'balanced'),param_grid,refit=True,verbose=0 )\n",
    "\n",
    "# get the data from layer 1 decode stim\n",
    "# this is a [trial x time step x unit] matrix\n",
    "data_d = data_unexpected['fr1']\n",
    "labs = data_unexpected['labs'].squeeze()\n",
    "labs = np.where(labs == 0, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d307e7a9-d31e-411e-a1e9-45febcac7297",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hkular/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/hkular/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV: 0, SVC(C=6.723357536499335e-05, class_weight='balanced', kernel='linear')\n",
      "CV: 1, SVC(C=6.723357536499335e-05, class_weight='balanced', kernel='linear')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hkular/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/hkular/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV: 2, SVC(C=6.723357536499335e-05, class_weight='balanced', kernel='linear')\n",
      "CV: 3, SVC(C=6.723357536499335e-05, class_weight='balanced', kernel='linear')\n",
      "CV: 4, SVC(C=6.2101694189156165, class_weight='balanced', kernel='linear')\n",
      "0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hkular/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    }
   ],
   "source": [
    "# avg over time window\n",
    "data_d = np.mean( data_d[ :,t_win[0]:t_win[1],: ], axis = 1 )\n",
    "\n",
    "# get some info about structure of the data\n",
    "tris = data_d.shape[0]             # number of trials\n",
    "tri_ind = np.arange(0,tris)      # list from 0...tris\n",
    "hold_out = int( tris / n_cvs )   # how many trials to hold out\n",
    "\n",
    "# loop over cvs and do classification\n",
    "for i in range(n_cvs):\n",
    "\n",
    "    # trials to hold out as test set on this cv fold\n",
    "    tst_ind = tri_ind[ i*hold_out : (i+1)*hold_out ]\n",
    "    \n",
    "    # index into the training data on this cv fold\n",
    "    trn_ind = np.setdiff1d( tri_ind, tst_ind )\n",
    "\n",
    "    # get the training data (X) and the training labels (y)\n",
    "    X = data_d[trn_ind,:]\n",
    "    y = labs[trn_ind]\n",
    "\n",
    "    # fit the model\n",
    "    grid.fit( X,y )\n",
    "\n",
    "    # progress report\n",
    "    print(f'CV: {i}, {grid.best_estimator_}')\n",
    "\n",
    "    # get the test data (X) and the test labels (y)\n",
    "    X_test = data_d[tst_ind, :]\n",
    "    y_test = labs[tst_ind]\n",
    "\n",
    "    # predict!\n",
    "    acc[ i ] = grid.score( X_test,y_test )\n",
    "        \n",
    "\n",
    "print( np.mean( acc ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805dd033-976b-4b59-9420-1406725f1ecf",
   "metadata": {},
   "source": [
    "______________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0b8ee7-e77f-4703-be61-9da1f1ca9f8f",
   "metadata": {},
   "source": [
    "______________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d9e220-375e-433d-bf79-41a08aa747d9",
   "metadata": {},
   "source": [
    "### Decode expected stim choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fb9ed9-613e-4301-a9f0-2103900c9a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_threshold(X, labs, thresh, model):\n",
    "  # Convert labels based on threshold\n",
    "  labs_binary = np.where(labs >= thresh, 1, 0)\n",
    "  \n",
    "  # Train-test split\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, labs_binary, test_size=0.2)\n",
    "  \n",
    "  # Fit the model\n",
    "  model.fit(X_train, y_train)\n",
    "  \n",
    "  # Evaluate on test set\n",
    "  predictions = model.predict(X_test)\n",
    "  accuracy = accuracy_score(y_test, predictions)\n",
    "  \n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7e2aa4ae-557e-4067-8a3d-63f01c1ca5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode trials: RNN stim choice\n",
    "\n",
    "# averge over this time window post stimulus\n",
    "# this is unit of model time-steps\n",
    "t_win = [ 200,-1 ]\n",
    "\n",
    "# number of cv folds\n",
    "n_cvs = 5\n",
    "\n",
    "# store the accuracy\n",
    "acc = np.full( ( n_cvs ), np.nan )\n",
    "\n",
    "# penalties to eval\n",
    "num_cgs = 30\n",
    "Cs = np.logspace( -5,1,num_cgs )\n",
    "\n",
    "# set up the grid\n",
    "param_grid = { 'C': Cs, 'kernel': ['linear'] }\n",
    "\n",
    "# define object - use a SVC that balances class weights (because they are biased, e.g. 70/30)\n",
    "# note that can also specify cv folds here, but I'm doing it by hand below in a loop\n",
    "grid = GridSearchCV( SVC(class_weight = 'balanced'),param_grid,refit=True,verbose=0 )\n",
    "\n",
    "# get the data from layer 1 decode choice\n",
    "# this is a [trial x time step x unit] matrix\n",
    "data_d = data_expected['fr1']\n",
    "labs = data_expected['outs'][:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "49f22c5b-4b85-473a-b857-574905326f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define threshold range (adjust as needed)\n",
    "thresholds = np.arange(0.1, 0.9, 0.05)\n",
    "\n",
    "# avg over time window\n",
    "data_d = np.mean( data_d[ :,t_win[0]:t_win[1], : ], axis = 1 )\n",
    "\n",
    "# get some info about structure of the data\n",
    "tris = data_d.shape[0]             # number of trials\n",
    "tri_ind = np.arange(0,tris)      # list from 0...tris\n",
    "hold_out = int( tris / n_cvs )   # how many trials to hold out\n",
    "\n",
    "\n",
    "# Initialize list to store accuracies\n",
    "best_thresh = None\n",
    "best_accuracy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0ac5ce22-d2a3-4afd-ba9f-1449ec954172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold: 0.6000000000000002, Best Accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "for thresh in thresholds:\n",
    "  # Within each cross-validation fold\n",
    "  for i in range(n_cvs):\n",
    "        \n",
    "    # trials to hold out as test set on this cv fold\n",
    "    tst_ind = tri_ind[ i*hold_out : (i+1)*hold_out ]\n",
    "    \n",
    "    # index into the training data on this cv fold\n",
    "    trn_ind = np.setdiff1d( tri_ind, tst_ind )\n",
    "\n",
    "    # get the training data (X) and the training labels (y)\n",
    "    # note that y is unbalanced unless prob is 50/50\n",
    "    X = data_d[ trn_ind,: ]\n",
    "    y = labs[ trn_ind ]\n",
    "\n",
    "    # Convert labels based on current threshold\n",
    "    y_binary = np.where( y >= thresh, 1, 0 )\n",
    "\n",
    "    # Fit the model on the binary labels\n",
    "    grid.fit( X, y_binary )\n",
    "    \n",
    "    # get the test data (X) and the test labels (y)\n",
    "    X_test = data_d[tst_ind, :]\n",
    "    y_test = labs[tst_ind]\n",
    "    y_test_binary = np.where( y_test >= thresh, 1, 0 )\n",
    "\n",
    "    # predict!\n",
    "    acc[ i ] = grid.score( X_test,y_test_binary )\n",
    "\n",
    "    # Evaluate accuracy\n",
    "    accuracy = np.mean( acc )\n",
    "\n",
    "    # Update optimal settings if needed\n",
    "    if accuracy > best_accuracy:\n",
    "      best_accuracy = accuracy\n",
    "      best_thresh = thresh\n",
    "\n",
    "  # Progress report after each threshold iteration\n",
    "  #print(f'Threshold: {thresh}, Accuracy: {accuracy}')\n",
    "\n",
    "# Print overall results\n",
    "print(f\"Optimal threshold: {best_thresh}, Best Accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd8003b-96de-4bf3-b724-eb63269a9e12",
   "metadata": {},
   "source": [
    "### Decode unexpected stim choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f67daf47-b4a7-47cf-b141-6bdd2ff5ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode trials: RNN stim choice\n",
    "\n",
    "# averge over this time window post stimulus\n",
    "# this is unit of model time-steps\n",
    "t_win = [ 200,-1 ]\n",
    "\n",
    "# number of cv folds\n",
    "n_cvs = 5\n",
    "\n",
    "# store the accuracy\n",
    "acc = np.full( ( n_cvs ), np.nan )\n",
    "\n",
    "# penalties to eval\n",
    "num_cgs = 30\n",
    "Cs = np.logspace( -5,1,num_cgs )\n",
    "\n",
    "# set up the grid\n",
    "param_grid = { 'C': Cs, 'kernel': ['linear'] }\n",
    "\n",
    "# define object - use a SVC that balances class weights (because they are biased, e.g. 70/30)\n",
    "# note that can also specify cv folds here, but I'm doing it by hand below in a loop\n",
    "grid = GridSearchCV( SVC(class_weight = 'balanced'),param_grid,refit=True,verbose=0 )\n",
    "\n",
    "# get the data from layer 1 decode choice\n",
    "# this is a [trial x time step x unit] matrix\n",
    "data_d = data_unexpected['fr1']\n",
    "labs = data_unexpected['outs'][:,-1]\n",
    "\n",
    "# Define threshold range (adjust as needed)\n",
    "thresholds = np.arange(0.1, 0.9, 0.05)\n",
    "\n",
    "# avg over time window\n",
    "data_d = np.mean( data_d[ :,t_win[0]:t_win[1], : ], axis = 1 )\n",
    "\n",
    "# get some info about structure of the data\n",
    "tris = data_d.shape[0]             # number of trials\n",
    "tri_ind = np.arange(0,tris)      # list from 0...tris\n",
    "hold_out = int( tris / n_cvs )   # how many trials to hold out\n",
    "\n",
    "\n",
    "# Initialize list to store accuracies\n",
    "best_thresh = None\n",
    "best_accuracy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bc506f9f-7048-4a9d-a12b-0181de3073f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.1, Accuracy: 0.79\n",
      "Threshold: 0.15000000000000002, Accuracy: 0.75\n",
      "Threshold: 0.20000000000000004, Accuracy: 0.8300000000000001\n",
      "Threshold: 0.25000000000000006, Accuracy: 0.8299999999999998\n",
      "Threshold: 0.30000000000000004, Accuracy: 0.85\n",
      "Threshold: 0.3500000000000001, Accuracy: 0.85\n",
      "Threshold: 0.40000000000000013, Accuracy: 0.7999999999999999\n",
      "Threshold: 0.45000000000000007, Accuracy: 0.7999999999999999\n",
      "Threshold: 0.5000000000000001, Accuracy: 0.55\n",
      "Threshold: 0.5500000000000002, Accuracy: 0.55\n",
      "Threshold: 0.6000000000000002, Accuracy: 0.7\n",
      "Threshold: 0.6500000000000001, Accuracy: 0.7\n",
      "Threshold: 0.7000000000000002, Accuracy: 0.7\n",
      "Threshold: 0.7500000000000002, Accuracy: 0.65\n",
      "Threshold: 0.8000000000000002, Accuracy: 0.65\n",
      "Threshold: 0.8500000000000002, Accuracy: 0.63\n",
      "Optimal threshold: 0.6000000000000002, Best Accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "for thresh in thresholds:\n",
    "  # Within each cross-validation fold\n",
    "  for i in range(n_cvs):\n",
    "        \n",
    "    # trials to hold out as test set on this cv fold\n",
    "    tst_ind = tri_ind[ i*hold_out : (i+1)*hold_out ]\n",
    "    \n",
    "    # index into the training data on this cv fold\n",
    "    trn_ind = np.setdiff1d( tri_ind, tst_ind )\n",
    "\n",
    "    # get the training data (X) and the training labels (y)\n",
    "    # note that y is unbalanced unless prob is 50/50\n",
    "    X = data_d[ trn_ind,: ]\n",
    "    y = labs[ trn_ind ]\n",
    "\n",
    "    # Convert labels based on current threshold\n",
    "    y_binary = np.where( y >= thresh, 1, 0 )\n",
    "\n",
    "    # Fit the model on the binary labels\n",
    "    grid.fit( X, y_binary )\n",
    "    \n",
    "    # get the test data (X) and the test labels (y)\n",
    "    X_test = data_d[tst_ind, :]\n",
    "    y_test = labs[tst_ind]\n",
    "    y_test_binary = np.where( y_test >= thresh, 1, 0 )\n",
    "\n",
    "    # predict!\n",
    "    acc[ i ] = grid.score( X_test,y_test_binary )\n",
    "\n",
    "    # Evaluate accuracy\n",
    "    accuracy = np.mean( acc )\n",
    "\n",
    "    # Update optimal settings if needed\n",
    "    if accuracy > best_accuracy:\n",
    "      best_accuracy = accuracy\n",
    "      best_thresh = thresh\n",
    "\n",
    "  # Progress report after each threshold iteration\n",
    "  print(f'Threshold: {thresh}, Accuracy: {accuracy}')\n",
    "\n",
    "# Print overall results\n",
    "print(f\"Optimal threshold: {best_thresh}, Best Accuracy: {best_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
