{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "008d1b4d-0315-41c2-b2c6-ad845afb47af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Decoding Progress:   0%|                                | 0/250 [01:17<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# testing starmap\n",
    "\n",
    "# import these are all needed for fnc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "from fnc_fit_and_score import fnc_fit_and_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from scipy.optimize import curve_fit\n",
    "import multiprocessing\n",
    "from tqdm import tqdm \n",
    "# what are we decoding\n",
    "RNN_params = {}\n",
    "RNN_params['prob_split'] = '70_30'\n",
    "RNN_params['afc'] = 2\n",
    "RNN_params['coh'] = 'hi'\n",
    "RNN_params['feedback'] = False\n",
    "RNN_params['thresh'] = [.3,.7]\n",
    "\n",
    "# Decoding params\n",
    "D_params = {}\n",
    "D_params['time_avg'] = False\n",
    "D_params['t_win'] = [200,-1]\n",
    "D_params['n_cvs'] = 5\n",
    "D_params['num_cgs'] = 30\n",
    "D_params['label'] = 'stim' # 'stim' or 'choice'\n",
    "\n",
    "# Load data\n",
    "if sys.platform.startswith('linux'):\n",
    "    data_dir = f\"/mnt/neurocube/local/serenceslab/holly/RNN_Geo/data/rdk_{RNN_params['prob_split']}_{RNN_params['afc']}afc/feedforward_only/{RNN_params['coh']}_coh\"\n",
    "else:\n",
    "    data_dir = f\"/Volumes/serenceslab/holly/RNN_Geo/data/rdk_{RNN_params['prob_split']}_{RNN_params['afc']}afc/feedforward_only/{RNN_params['coh']}_coh\"\n",
    "\n",
    "# Change this if we want a different number of trials and different default stim (0 is the one RNN was trained on)\n",
    "data_file = f\"{data_dir}/Trials200_0expected.npz\"\n",
    "\n",
    "# Timing of task\n",
    "task_info = {}\n",
    "task_info['trials'] = 200\n",
    "task_info['trial_dur'] = 250  # trial duration (timesteps)\n",
    "task_info['stim_on'] = 80\n",
    "task_info['stim_dur'] = 50\n",
    "\n",
    "save_plt = False\n",
    "prob_split = RNN_params.get('prb_split', '70_30')\n",
    "afc = RNN_params.get('afc', 2)\n",
    "coh = RNN_params.get('coh', 'hi')\n",
    "feedback = RNN_params.get('feedback', False)\n",
    "thresh = RNN_params.get('thresh', [.3, .7])\n",
    "time_avg = D_params.get('time_avg', False)\n",
    "t_win = D_params.get('t_win', [200, -1])\n",
    "label = D_params.get('label', 'stim')\n",
    "n_cvs = D_params.get('n_cvs', 5)\n",
    "num_cgs = D_params.get('num_cgs', 30)\n",
    "# penalties to eval\n",
    "Cs = np.logspace( -5,1, num_cgs )\n",
    "\n",
    "# store the accuracy\n",
    "acc = np.full( ( n_cvs ), np.nan )\n",
    "\n",
    "# set up the grid\n",
    "param_grid = { 'C': Cs, 'kernel': ['linear'] }\n",
    "\n",
    "# define object - use a SVC that balances class weights (because they are biased, e.g. 70/30)\n",
    "# note that can also specify cv folds here, but I'm doing it by hand below in a loop\n",
    "grid = GridSearchCV( SVC(class_weight = 'balanced'),param_grid,refit=True,verbose=0 )\n",
    "\n",
    "# load data\n",
    "data = np.load(data_file)\n",
    "\n",
    "# set-up vars for decoding   \n",
    "data_d = data['fr1']# layer 1 firing rate [trial x time step x unit] matrix\n",
    "labs = data['labs'].squeeze()\n",
    "\n",
    "# get some info about structure of the data\n",
    "tris = data_d.shape[0]             # number of trials\n",
    "tri_ind = np.arange(0,tris)      # list from 0...tris\n",
    "hold_out = int( tris / n_cvs )   # how many trials to hold out\n",
    "# pre-allocate\n",
    "decoding_acc = np.nan\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = Pool(processes=round(os.cpu_count() * .7))\n",
    "    with pool:  # use 70% of cpus\n",
    "        results = pool.starmap(fnc_fit_and_score, [\n",
    "            (t_step, data_d[:, t_step, :], tri_ind, hold_out, n_cvs, labs, label, thresh, grid)\n",
    "            for t_step in range(task_info['trial_dur'])\n",
    "        ], chunksize = 10)\n",
    "\n",
    "    # Process the results from each worker process (list of lists of accuracies)\n",
    "    decoding_acc = np.mean(np.array(results), axis=1)  # Calculate mean accuracy for each time step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631ab11a-5978-4fee-8539-1e5c8c873c93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
