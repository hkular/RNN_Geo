{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590e25cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.io import loadmat\n",
    "from multiprocessing import Pool\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e902e4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_params = {\n",
    "    'prob_split': '70_30',\n",
    "    'afc': [6, 2],\n",
    "    'coh': ['hi', 'lo'],\n",
    "    'feedback': False,\n",
    "    'thresh': [.3, .7],\n",
    "    'model': [0, 1 ,2],\n",
    "    'fr': [1,3]\n",
    "}\n",
    "\n",
    "D_params = {\n",
    "    'time_avg': False,\n",
    "    't_win': [130, -1],\n",
    "    'n_cvs': 5,\n",
    "    'num_cgs': 30,\n",
    "    'label': 'stim',  \n",
    "    'units': 'all',  # 'all' or 'exc' or 'inh'\n",
    "    'pred': 'unexpected'  # 'expected' or 'unexpected', 'neutral' MODIFY HERE\n",
    "}\n",
    "\n",
    "# Timing of task\n",
    "task_info = {\n",
    "    'trials': 1000,\n",
    "    'trial_dur': 250,\n",
    "    'stim_on': 80,\n",
    "    'stim_dur': 50\n",
    "}\n",
    "\n",
    "window = 50 # size of time window to get sliding avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87da78fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# define sliding window of times to decode\n",
    "def fnc_sliding_window(elements, window_size):\n",
    "    \"\"\"\n",
    "    Description: create time windows to decode over\n",
    "    Returns: [times]\n",
    "    \"\"\"\n",
    "    if len(elements) <= window_size:\n",
    "        return elements\n",
    "    \n",
    "    windows = []\n",
    "    for i in range(len(elements) - window_size + 1):\n",
    "      windows.append(elements[i:i + window_size])\n",
    "    \n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5545c303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SVM \n",
    "n_cvs = 3\n",
    "# penalties to eval\n",
    "num_cgs = 15\n",
    "Cs = np.logspace(-5,1,num_cgs )\n",
    "\n",
    "# set up the grid\n",
    "param_grid = { 'C': Cs, 'kernel': ['linear'] }\n",
    "\n",
    "# define object - use a SVC that balances class weights (because they are biased, e.g. 70/30)\n",
    "# note that can also specify cv folds here, but I'm doing it by hand below\n",
    "grid = GridSearchCV( SVC(class_weight = 'balanced'),param_grid,refit=True,verbose=0, n_jobs=-1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c94c058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------\n",
    "# define loop to decode over times and run boot strap samples over\n",
    "\n",
    "def fnc_decode_times(n_boot, task_info, data_d, tri_ind, hold_out, n_cvs, afc, labs, D_params, thresh, grid):\n",
    "    \"\"\"\n",
    "    Description: loop decoding over each time window\n",
    "    Returns: [acc, class, t_step]\n",
    "    \"\"\"\n",
    "    np.random.seed(n_boot)  # Ensure each bootstrap is different\n",
    "    results = []\n",
    "    times = task_info['trial_dur']\n",
    "    for t in range(times):\n",
    "        print(t)\n",
    "        seed = np.random.randint(0, 1000000)  # Unique seed for each time point within the bootstrap\n",
    "        result = fnc_fit_and_score(data_d[:, t, :], tri_ind, hold_out, n_cvs, afc, labs, D_params['label'], thresh, grid, seed)\n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc6421c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------\n",
    "# define decoding\n",
    "\n",
    "def fnc_fit_and_score(data_slice, tri_ind, hold_out, n_cvs, afc, labs, label, thresh, grid, seeds):\n",
    "    \"\"\"\n",
    "    Description: Script for decoding fitting linear SVM and scoring accuracy across CV folds\n",
    "    Fits the model on each CV fold for a given time step\n",
    "    Returns: [acc, class]\n",
    "    \"\"\"\n",
    "    #np.random.seed(seeds)  # Initialize the random number generator with the given seed\n",
    "    acc = np.zeros(n_cvs)\n",
    "    cm = np.zeros((n_cvs, afc))\n",
    "      \n",
    "    for i in range(n_cvs):\n",
    "        # trials to hold out as test set on this cv fold\n",
    "        tst_ind = tri_ind[ i*hold_out : (i+1)*hold_out ]\n",
    "        trn_ind = np.random.choice(np.setdiff1d(tri_ind, tst_ind), size = len(np.setdiff1d(tri_ind, tst_ind)), replace = True)\n",
    "        \n",
    "        # get the training data (X) and the training labels (y)\n",
    "        X = data_slice[trn_ind,:]\n",
    "        y = labs[trn_ind]\n",
    "        \n",
    "        # fit the model\n",
    "        grid.fit(X, y)\n",
    "\n",
    "        # get the test data (X) and the test labels (y)\n",
    "        X_test = data_slice[tst_ind, :]\n",
    "        y_test = labs[tst_ind]\n",
    "\n",
    "        # predict and score\n",
    "        y_pred = grid.predict(X_test)\n",
    "        cm[i] = confusion_matrix(y_test, y_pred, normalize = \"true\").diagonal()\n",
    "        \n",
    "    acc = np.mean(cm, axis = 0) # acg across cvs\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669ce64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a wrapper function to pass additional arguments\n",
    "def parallel_fnc_decode_times(i):\n",
    "    return fnc_decode_times(i, task_info, data_d, tri_ind, hold_out, n_cvs, 6, labs, D_params, thresh, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f65f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now actually do decoding across conditions\n",
    "\n",
    "modelnum = 0 # which model do we want \n",
    "nboots = 20 # how many boot strap samples do we want?\n",
    "\n",
    "combinations = list(itertools.product(RNN_params['afc'], RNN_params['coh'], RNN_params['fr']))\n",
    "cwd = os.getcwd()\n",
    "\n",
    "start_time = time.time()\n",
    "i = 0\n",
    "fr = 1\n",
    "data_dir = os.path.join(cwd, 'data', D_params['pred'])\n",
    "data = np.load(os.path.join(data_dir, 'Trials1000_model536_unexpected.npz'))\n",
    "data_d = data[f'fr{fr}'] # this is a [trial x time step x unit] matrix\n",
    "# get some info about structure of the data\n",
    "labs = data['labs'].squeeze() # [trial x time step]\n",
    "tris = data_d.shape[0]             # number of trials\n",
    "tri_ind = np.arange(0,tris)      # list from 0...tris\n",
    "hold_out = int( tris / n_cvs )   # how many trials to hold out\n",
    "thresh = RNN_params.get('thresh', [.3, .7])\n",
    "fnc_decode_times(i, task_info, data_d, tri_ind, hold_out, n_cvs, 6, labs, D_params, thresh, grid)\n",
    "#with Pool(processes=round(os.cpu_count() * .9)) as pool:\n",
    "    #results = pool.map(parallel_fnc_decode_times, range(nboots))\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfb2d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6874302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many hours for 1000 bootstrap iterations\n",
    "258*1000/60/60/5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee8ce84",
   "metadata": {},
   "source": [
    "### Servers\n",
    "- `duckee`\n",
    "- `morton`\n",
    "- `wells`\n",
    "- `scarlett`\n",
    "- `nikola`\n",
    "- `ruska`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cebra",
   "language": "python",
   "name": "cebra"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
