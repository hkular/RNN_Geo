{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "290d8cb1-c449-4aa8-bbd7-d60118163356",
   "metadata": {},
   "source": [
    "Name: Holly Kular\\\n",
    "Date: 03-19-2024\\\n",
    "Email: hkular@ucsd.edu\\\n",
    "decode_L1_stimvschoice\\\n",
    "Description: Script for decoding analysis on layer 1 of probabilistic RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "000af540-4a71-4886-8250-9bdfbdfa74f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0210ed5e-58cc-4e61-a61a-8ae298c19094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_classification  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b585d928-bf9e-46a9-a2ba-d77873aa5bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFY HERE\n",
    "# what conditions were the RNNs trained on?\n",
    "prob_split = '70_30' # the probability of stimulus 1 vs all\n",
    "afc = '6' # number of alternatives\n",
    "coh = 'lo' # coherence\n",
    "feedback = False # interlayer feedback (true or false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9a68920d-f067-4e10-a8f1-158f6f447bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Directory\n",
    "if sys.platform.startswith('linux'):\n",
    "    data_dir = f\"/mnt/neurocube/local/serenceslab/holly/RNN_Geo/data/rdk_{prob_split}_{afc}afc/feedforward_only/{coh}_coh\"\n",
    "else:\n",
    "    data_dir = f\"/Volumes/serenceslab/holly/RNN_Geo/data/rdk_{prob_split}_{afc}afc/feedforward_only/{coh}_coh\"\n",
    "\n",
    "# Load data\n",
    "#data = np.load(f\"{data_dir}/Trials.npz\")\n",
    "data = np.load(f\"{data_dir}/Trials_0expected.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79b80693-7dbc-403f-839d-20af277a00fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['fr1'] data['outs'] data['labs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327c746c-1c31-4ad1-a8ec-89734d99fd99",
   "metadata": {},
   "source": [
    "## Compare decode choice vs. stim\n",
    "Hypothesis: We can decode stimulus better than choice from layer 1 because of a more sensory-like format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a8789816-115f-461e-a6df-f00cbdc9049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_threshold(X, labs, thresh, model):\n",
    "  # Convert labels based on threshold\n",
    "  labs_binary = np.where(labs >= thresh, 1, 0)\n",
    "  \n",
    "  # Train-test split\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, labs_binary, test_size=0.2)\n",
    "  \n",
    "  # Fit the model\n",
    "  model.fit(X_train, y_train)\n",
    "  \n",
    "  # Evaluate on test set\n",
    "  predictions = model.predict(X_test)\n",
    "  accuracy = accuracy_score(y_test, predictions)\n",
    "  \n",
    "  return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee5aa49-64f7-4a6f-92f1-fa298955f070",
   "metadata": {},
   "source": [
    "### Decode choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "865d2939-19b4-4447-8931-404ecf2d8ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode trials: RNN stim choice\n",
    "\n",
    "# averge over this time window post stimulus\n",
    "# this is unit of model time-steps\n",
    "t_win = [ 200,-1 ]\n",
    "\n",
    "# number of cv folds\n",
    "n_cvs = 5\n",
    "\n",
    "# store the accuracy\n",
    "acc = np.full( ( n_cvs ), np.nan )\n",
    "\n",
    "# penalties to eval\n",
    "num_cgs = 30\n",
    "Cs = np.logspace( -5,1,num_cgs )\n",
    "\n",
    "# set up the grid\n",
    "param_grid = { 'C': Cs, 'kernel': ['linear'] }\n",
    "\n",
    "# define object - use a SVC that balances class weights (because they are biased, e.g. 70/30)\n",
    "# note that can also specify cv folds here, but I'm doing it by hand below in a loop\n",
    "grid = GridSearchCV( SVC(class_weight = 'balanced'),param_grid,refit=True,verbose=0 )\n",
    "\n",
    "# get the data from layer 1 decode choice\n",
    "# this is a [trial x time step x unit] matrix\n",
    "data_d = data['fr1']\n",
    "labs = data['outs'][:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4c7e15f8-27fe-4ba1-b37f-db09e59d687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define threshold range (adjust as needed)\n",
    "thresholds = np.arange(0.1, 0.9, 0.05)\n",
    "\n",
    "# avg over time window\n",
    "data_d = np.mean( data_d[ :,t_win[0]:t_win[1], : ], axis = 1 )\n",
    "\n",
    "# get some info about structure of the data\n",
    "tris = data_d.shape[0]             # number of trials\n",
    "tri_ind = np.arange(0,tris)      # list from 0...tris\n",
    "hold_out = int( tris / n_cvs )   # how many trials to hold out\n",
    "\n",
    "\n",
    "# Initialize list to store accuracies\n",
    "best_thresh = None\n",
    "best_accuracy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c1ba66ff-804b-4f94-9c55-df3fc4981464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold: 0.30000000000000004, Best Accuracy: 0.7699999999999999\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for thresh in thresholds:\n",
    "  # Within each cross-validation fold\n",
    "  for i in range(n_cvs):\n",
    "        \n",
    "    # trials to hold out as test set on this cv fold\n",
    "    tst_ind = tri_ind[ i*hold_out : (i+1)*hold_out ]\n",
    "    \n",
    "    # index into the training data on this cv fold\n",
    "    trn_ind = np.setdiff1d( tri_ind, tst_ind )\n",
    "\n",
    "    # get the training data (X) and the training labels (y)\n",
    "    # note that y is unbalanced unless prob is 50/50\n",
    "    X = data_d[ trn_ind,: ]\n",
    "    y = labs[ trn_ind ]\n",
    "\n",
    "    # Convert labels based on current threshold\n",
    "    y_binary = np.where( y >= thresh, 1, 0 )\n",
    "\n",
    "    # Fit the model on the binary labels\n",
    "    grid.fit( X, y_binary )\n",
    "    \n",
    "    # get the test data (X) and the test labels (y)\n",
    "    X_test = data_d[tst_ind, :]\n",
    "    y_test = labs[tst_ind]\n",
    "    y_test_binary = np.where( y_test >= thresh, 1, 0 )\n",
    "\n",
    "    # predict!\n",
    "    acc[ i ] = grid.score( X_test,y_test_binary )\n",
    "\n",
    "    # Evaluate accuracy\n",
    "    accuracy = np.mean( acc )\n",
    "\n",
    "    # Update optimal settings if needed\n",
    "    if accuracy > best_accuracy:\n",
    "      best_accuracy = accuracy\n",
    "      best_thresh = thresh\n",
    "\n",
    "  # Progress report after each threshold iteration\n",
    "  #print(f'Threshold: {thresh}, Accuracy: {accuracy}')\n",
    "\n",
    "# Print overall results\n",
    "print(f\"Optimal threshold: {best_thresh}, Best Accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8114da-64b8-40a5-ad57-0b51bbaf6be6",
   "metadata": {},
   "source": [
    "### Decode stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "87962003-7368-4e72-ad63-aa3e3972675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode trials: RNN stim presented\n",
    "\n",
    "# averge over this time window post stimulus\n",
    "# this is unit of model time-steps\n",
    "t_win = [ 200,-1 ]\n",
    "\n",
    "# number of cv folds\n",
    "n_cvs = 5\n",
    "\n",
    "# store the accuracy\n",
    "acc = np.full( ( n_cvs ), np.nan )\n",
    "\n",
    "# penalties to eval\n",
    "num_cgs = 30\n",
    "Cs = np.logspace( -5,1,num_cgs )\n",
    "\n",
    "# set up the grid\n",
    "param_grid = { 'C': Cs, 'kernel': ['linear'] }\n",
    "\n",
    "# define object - use a SVC that balances class weights (because they are biased, e.g. 70/30)\n",
    "# note that can also specify cv folds here, but I'm doing it by hand below in a loop\n",
    "grid = GridSearchCV( SVC(class_weight = 'balanced'),param_grid,refit=True,verbose=0 )\n",
    "\n",
    "# get the data from layer 1 decode stim\n",
    "# this is a [trial x time step x unit] matrix\n",
    "data_d = data['fr1']\n",
    "labs = data['labs'].squeeze()\n",
    "#labs = np.where(labs == 0, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5d5557f4-a8cf-42dd-a5cf-0f0d164a869d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV: 0, SVC(C=6.2101694189156165, class_weight='balanced', kernel='linear')\n",
      "CV: 1, SVC(C=3.856620421163472, class_weight='balanced', kernel='linear')\n",
      "CV: 2, SVC(C=1.610262027560939e-05, class_weight='balanced', kernel='linear')\n",
      "CV: 3, SVC(C=4.1753189365604006e-05, class_weight='balanced', kernel='linear')\n",
      "CV: 4, SVC(C=10.0, class_weight='balanced', kernel='linear')\n",
      "0.7399999999999999\n"
     ]
    }
   ],
   "source": [
    "# avg over time window\n",
    "data_d = np.mean( data_d[ :,t_win[0]:t_win[1],: ], axis = 1 )\n",
    "\n",
    "# get some info about structure of the data\n",
    "tris = data_d.shape[0]             # number of trials\n",
    "tri_ind = np.arange(0,tris)      # list from 0...tris\n",
    "hold_out = int( tris / n_cvs )   # how many trials to hold out\n",
    "\n",
    "# loop over cvs and do classification\n",
    "for i in range(n_cvs):\n",
    "\n",
    "    # trials to hold out as test set on this cv fold\n",
    "    tst_ind = tri_ind[ i*hold_out : (i+1)*hold_out ]\n",
    "    \n",
    "    # index into the training data on this cv fold\n",
    "    trn_ind = np.setdiff1d( tri_ind, tst_ind )\n",
    "\n",
    "    # get the training data (X) and the training labels (y)\n",
    "    X = data_d[trn_ind,:]\n",
    "    y = labs[trn_ind]\n",
    "\n",
    "    # fit the model\n",
    "    grid.fit( X,y )\n",
    "\n",
    "    # progress report\n",
    "    print(f'CV: {i}, {grid.best_estimator_}')\n",
    "\n",
    "    # get the test data (X) and the test labels (y)\n",
    "    X_test = data_d[tst_ind, :]\n",
    "    y_test = labs[tst_ind]\n",
    "\n",
    "    # predict!\n",
    "    acc[ i ] = grid.score( X_test,y_test )\n",
    "        \n",
    "\n",
    "print( np.mean( acc ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb644bd5-8ef5-4d48-9f89-366eef55256b",
   "metadata": {},
   "source": [
    "______________________________________________________________________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
