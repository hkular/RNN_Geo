{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3d59a93-39f4-47c6-86c7-5dbfde890d17",
   "metadata": {},
   "source": [
    "Name: Holly Kular\\\n",
    "Date: 03-19-2024\\\n",
    "Email: hkular@ucsd.edu\\\n",
    "decode_L1.m\\\n",
    "Description: Script for decoding analysis on layer 1 of probabilistic RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79f6a786-a74f-4995-9f98-ccdbe0e06f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e0d19cc-8088-4ab9-9c23-9eedda5003dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFY HERE\n",
    "# what conditions were the RNNs trained on?\n",
    "RNN_params = {}\n",
    "RNN_params['prob_split'] = '70_30'\n",
    "RNN_params['afc'] = 2\n",
    "RNN_params['coh'] = 'hi'\n",
    "RNN_params['feedback'] = False\n",
    "RNN_params['thresh'] = [.3,.7]\n",
    "\n",
    "# Decoding params\n",
    "D_params = {}\n",
    "D_params['time_avg'] = False\n",
    "D_params['t_win'] = [200,-1]\n",
    "D_params['n_cvs'] = 5\n",
    "D_params['num_cgs'] = 30\n",
    "D_params['label'] = 'stim' # 'stim' or 'choice'\n",
    "D_params['units'] = 'all' # 'all' or 'exc' or 'inh'\n",
    "D_params['pred'] = 'expected' # 'expected' or 'unexpected', trials had stim 0 or 1 dominant\n",
    "\n",
    "# Timing of task\n",
    "task_info = {}\n",
    "task_info['trials'] = 1000\n",
    "task_info['trial_dur'] = 250  # trial duration (timesteps)\n",
    "task_info['stim_on'] = 80\n",
    "task_info['stim_dur'] = 50\n",
    "# decode opts\n",
    "time_avg = False # do we want to look at average over time window?\n",
    "if time_avg:\n",
    "    t_win = [ 200,-1 ]\n",
    "n_cvs = 5\n",
    "window = 25\n",
    "# store the accuracy\n",
    "acc = np.full( ( n_cvs ), np.nan )\n",
    "\n",
    "# penalties to eval\n",
    "num_cgs = 30\n",
    "Cs = np.logspace( -5,1,num_cgs )\n",
    "\n",
    "# set up the grid\n",
    "param_grid = { 'C': Cs, 'kernel': ['linear'] }\n",
    "\n",
    "# define object - use a SVC that balances class weights (because they are biased, e.g. 70/30)\n",
    "# note that can also specify cv folds here, but I'm doing it by hand below in a loop\n",
    "grid = GridSearchCV( SVC(class_weight = 'balanced'),param_grid,refit=True,verbose=0 )\n",
    "\n",
    "# Data Directory\n",
    "# Load data\n",
    "if sys.platform.startswith('linux'):\n",
    "    data_dir = f\"/mnt/neurocube/local/serenceslab/holly/RNN_Geo/data/rdk_{RNN_params['prob_split']}_{RNN_params['afc']}afc/feedforward_only/{RNN_params['coh']}_coh\"\n",
    "else:\n",
    "    data_dir = f\"/Volumes/serenceslab/holly/RNN_Geo/data/rdk_{RNN_params['prob_split']}_{RNN_params['afc']}afc/feedforward_only/{RNN_params['coh']}_coh\"\n",
    "\n",
    "# Chose the model\n",
    "mat_files = [f for f in os.listdir(data_dir) if f.endswith('.mat')]# Get all the trained models (should be 40 .mat files)\n",
    "model_path = os.path.join(data_dir, mat_files[0]) \n",
    "model = loadmat(model_path) # model.keys()\n",
    "\n",
    "# Change this if we want a different number of trials and different default stim (0 is the one RNN was trained on)\n",
    "if D_params['pred'] == 'expected':\n",
    "    data_file = f\"{data_dir}/Trials{task_info['trials']}_model{model_path[-7:-4]}_0expected.npz\"\n",
    "elif D_params['pred'] == 'unexpected':\n",
    "    data_file = f\"{data_dir}/Trials{task_info['trials']}_model{model_path[-7:-4]}_1unexpected.npz\"\n",
    "data = np.load(data_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dbe0f31-71ed-4292-9d3e-a8cb5ba18c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode trials: RNN stim presented\n",
    "\n",
    "# get the data from layer 1 decode stim\n",
    "# this is a [trial x time step x unit] matrix\n",
    "data_d = data['fr1']\n",
    "labs = data['labs'].squeeze()\n",
    "\n",
    "# get some info about structure of the data\n",
    "tris = data_d.shape[0]             # number of trials\n",
    "tri_ind = np.arange(0,tris)      # list from 0...tris\n",
    "hold_out = int( tris / n_cvs )   # how many trials to hold out\n",
    "\n",
    "# filter by trial type\n",
    "# TODO make sure expected only has expected and unexpected only has unexpected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b482eec4-0546-4a55-9444-b34caf490694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(elements, window_size):\n",
    "  if len(elements) <= window_size:\n",
    "    return elements\n",
    "\n",
    "  windows = []\n",
    "  for i in range(len(elements) - window_size + 1):\n",
    "    windows.append(elements[i:i + window_size])\n",
    "\n",
    "  return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b75cae6-c1f6-46cd-8797-c51a41910d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do decoding \n",
    "decoding_acc = np.zeros((len(range(task_info['stim_dur']+task_info['stim_on'],task_info['trial_dur'])),))\n",
    "\n",
    "times = sliding_window(range(task_info['stim_dur']+task_info['stim_on'],task_info['trial_dur']), window)\n",
    "counter = 0\n",
    "for t in times:\n",
    "\n",
    "  # Get data slice for the current window avg\n",
    "    data_slice = np.mean( data_d[:,t, :], axis = 1 )\n",
    "\n",
    "    # loop over cvs and do classification\n",
    "    for i in range(n_cvs):\n",
    "\n",
    "        # trials to hold out as test set on this cv fold\n",
    "        tst_ind = tri_ind[ i*hold_out : (i+1)*hold_out ]\n",
    "\n",
    "        # index into the training data on this cv fold\n",
    "        trn_ind = np.setdiff1d( tri_ind, tst_ind )\n",
    "\n",
    "        # get the training data (X) and the training labels (y)\n",
    "        X = data_slice[trn_ind,:]\n",
    "        y = labs[trn_ind]\n",
    "\n",
    "        # fit the model\n",
    "        grid.fit( X,y )\n",
    "\n",
    "        # progress report\n",
    "        #print(f'CV: {i}, {grid.best_estimator_}')\n",
    "\n",
    "        # get the test data (X) and the test labels (y)\n",
    "        X_test = data_slice[tst_ind, :]\n",
    "        y_test = labs[tst_ind]\n",
    "\n",
    "        # predict!\n",
    "        acc[ i ] = grid.score( X_test,y_test )\n",
    "    counter +=1\n",
    "    decoding_acc[counter] = np.mean(acc)        \n",
    "        \n",
    "print(f'done decoding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953c1a23-a294-4dbe-b042-1b4894589429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot decoding accuracy over time\n",
    "    plt.figure()\n",
    "    plt.plot(range(task_info['stim_dur']+task_info['stim_on'],task_info['trial_dur']), decoding_acc)\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Decoding Accuracy')\n",
    "    plt.title('Decoding Accuracy Over Time')\n",
    "    plt.axvspan(task_info['stim_on'], task_info['stim_on']+task_info['stim_dur'], color = 'gray', alpha = 0.3)\n",
    "    #plt.savefig(f\"{data_dir}/decode_stim_exp.png\")\n",
    "    plt.show()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
