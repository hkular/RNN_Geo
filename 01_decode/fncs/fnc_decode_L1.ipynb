{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b585d928-bf9e-46a9-a2ba-d77873aa5bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnc_decode_L1(RNN_params, D_params, data_file, task_info):\n",
    "    '''\n",
    "Name: Holly Kular\n",
    "Date: 03-19-2024\n",
    "Email: hkular@ucsd.edu\n",
    "fnc_decode_L1.py\n",
    "Description: Script for decoding analysis on layer 1 of probabilistic RNN\n",
    "\n",
    "    INPUT\n",
    "    RNN_params (dict)\n",
    "       - prob_split: what was the split of the dominant stim vs all (default '70_30')\n",
    "       - afc: number of alternatives (2 or 6) (default 2)\n",
    "       - coh: what was the coherence of RDK (default 'hi')\n",
    "       - feedback: interlayer feedback (true or false) (default false)\n",
    "       - thresh: the threshold to label RNN output (default [.3, .7])\n",
    "\n",
    "    D_params (dict)\n",
    "       - time_avg: whether we want decoding averaged over time or not (true or false) (default false)\n",
    "       - t_win: what time window to average over if time_avg = true (default [200,-1])\n",
    "       - n_cvs: cross validation folds (default 5)\n",
    "       - num_cgs: penalties to eval (default 30)\n",
    "\n",
    "    data_file: file path for Trials that we want to load\n",
    "    '''\n",
    "    # set up defaults\n",
    "    prob_split = RNN_params.get('prb_split', '70_30')\n",
    "    afc = RNN_params.get('afc', 2)\n",
    "    coh = RNN_params.get('coh', 'hi')\n",
    "    feedback = RNN_params.get('feedback', False)\n",
    "    thresh = RNN_params.get('thresh', [.3, .7])\n",
    "    time_avg = D_params.get('time_avg', False)\n",
    "    t_win = D_params.get('t_win', [200, -1])\n",
    "    label = D_params.get('label', 'stim')\n",
    "    n_cvs = D_params.get('n_cvs', 5)\n",
    "    num_cgs = D_params.get('num_cgs', 30)\n",
    "    # penalties to eval\n",
    "    Cs = np.logspace( -5,1, num_cgs )\n",
    "    \n",
    "    # store the accuracy\n",
    "    acc = np.full( ( n_cvs ), np.nan )\n",
    "\n",
    "    # set up the grid\n",
    "    param_grid = { 'C': Cs, 'kernel': ['linear'] }\n",
    "\n",
    "    # define object - use a SVC that balances class weights (because they are biased, e.g. 70/30)\n",
    "    # note that can also specify cv folds here, but I'm doing it by hand below in a loop\n",
    "    grid = GridSearchCV( SVC(class_weight = 'balanced'),param_grid,refit=True,verbose=0 )\n",
    "    \n",
    "    # load data\n",
    "    data = np.load(data_file)\n",
    "    \n",
    "    # set-up vars for decoding   \n",
    "    data_d = data['fr1']# layer 1 firing rate [trial x time step x unit] matrix\n",
    "    labs = data['labs'].squeeze()\n",
    "\n",
    "    # get some info about structure of the data\n",
    "    tris = data_d.shape[0]             # number of trials\n",
    "    tri_ind = np.arange(0,tris)      # list from 0...tris\n",
    "    hold_out = int( tris / n_cvs )   # how many trials to hold out\n",
    "    \n",
    "    if time_avg: # if we are doing average over time there's no need to run in parallel\n",
    "        \n",
    "        data_d = np.mean( data_d[ :,t_win[0]:t_win[1],: ], axis = 1 ) # average over time window\n",
    "        # Within each cross-validation fold\n",
    "        for i in range(n_cvs):\n",
    "\n",
    "            # trials to hold out as test set on this cv fold\n",
    "            tst_ind = tri_ind[ i*hold_out : (i+1)*hold_out ]\n",
    "\n",
    "            # index into the training data on this cv fold\n",
    "            trn_ind = np.setdiff1d( tri_ind, tst_ind )\n",
    "\n",
    "            # get the training data (X) and the training labels (y)\n",
    "            # note that y is unbalanced unless prob is 50/50\n",
    "            X = data_d[ trn_ind,: ]\n",
    "            y = labs[trn_ind]\n",
    "\n",
    "            # Fit the model on the binary labels\n",
    "            grid.fit( X, y )\n",
    "\n",
    "            # get the test data (X) and the test labels (y)\n",
    "            X_test = data_d[tst_ind, :]\n",
    "            y_test = labs[tst_ind]\n",
    "\n",
    "            # predict!\n",
    "            acc[ i ] = grid.score( X_test,y_test )\n",
    "\n",
    "        # Evaluate accuracy\n",
    "        return decoding_acc = np.mean( acc ) \n",
    "        \n",
    "    else: # if we are decoding each time step, run that in parallel\n",
    "        \n",
    "        if __name__ == \"__main__\":\n",
    "\n",
    "            with Pool(processes=round(os.cpu_count()*.7)):  # use 70% of cpus\n",
    "                results = pool.starmap(fnc_fit_and_score, [\n",
    "                    (t_step, data_d[:, t_step, :], tri_ind, hold_out, n_cvs, labs, label, thresh, grid)\n",
    "                    for t_step in range(task_info['trial_dur'])\n",
    "                ], chunksize = 10)\n",
    "\n",
    "            # Process the results from each worker process (list of lists of accuracies)\n",
    "            return decoding_acc = np.mean(np.array(results), axis=1)  # Calculate mean accuracy for each time step\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
