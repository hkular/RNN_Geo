{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8272f048-ffeb-406f-8d93-774b64fb14c5",
   "metadata": {},
   "source": [
    "Name: Holly Kular\\\n",
    "Date: 08-14-2024\\\n",
    "Email: hkular@ucsd.edu\\\n",
    "Description: decoding RNN firing rate and trial type, garbage in garbage out version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb1bfc2f-b5d6-4197-965e-c60c35b46a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.io import loadmat\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8488462-fc5a-4096-86a7-9ae811342680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN timing and info\n",
    "\n",
    "RNN_params = {\n",
    "    'prob_split': '70_30',\n",
    "    'afc': [6, 2],\n",
    "    'coh': ['hi', 'lo'],\n",
    "    'feedback': False,\n",
    "    'thresh': [.3, .7],\n",
    "    'model': [0, 1 ,2],\n",
    "    'fr': [1,3]\n",
    "}\n",
    "\n",
    "D_params = {\n",
    "    'time_avg': False,\n",
    "    't_win': [130, -1],\n",
    "    'n_cvs': 5,\n",
    "    'num_cgs': 30,\n",
    "    'label': 'stim',  \n",
    "    'units': 'all',  # 'all' or 'exc' or 'inh'\n",
    "    'pred': 'neutral'  # 'expected' or 'unexpected', 'neutral'\n",
    "}\n",
    "# Timing of task\n",
    "task_info = {\n",
    "    'trials': 1000,\n",
    "    'trial_dur': 250,\n",
    "    'stim_on': 80,\n",
    "    'stim_dur': 50\n",
    "}\n",
    "\n",
    "window = 50 # size of time window to get sliding avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c693496c-1d13-46c6-8e45-0dfbb59d68c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SVM \n",
    "\n",
    "n_cvs = 5\n",
    "# penalties to eval\n",
    "num_cgs = 30\n",
    "Cs = np.logspace( -5,1,num_cgs )\n",
    "\n",
    "# set up the grid\n",
    "param_grid = { 'C': Cs, 'kernel': ['linear'] }\n",
    "\n",
    "# define object - use a SVC that balances class weights (because they are biased, e.g. 70/30)\n",
    "# note that can also specify cv folds here, but I'm doing it by hand below\n",
    "grid = GridSearchCV( SVC(class_weight = 'balanced'),param_grid,refit=True,verbose=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "915b84fb-1e3e-4027-8414-c05d6a662dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom funcs\n",
    "# ------------------------------------------------------------------------------\n",
    "# define sliding window of times to decode\n",
    "\n",
    "def fnc_sliding_window(elements, window_size):\n",
    "    \"\"\"\n",
    "    Description: create time windows to decode over\n",
    "    Returns: [times]\n",
    "    \"\"\"\n",
    "    if len(elements) <= window_size:\n",
    "        return elements\n",
    "\n",
    "    windows = []\n",
    "    for i in range(len(elements) - window_size + 1):\n",
    "        windows.append(elements[i:i + window_size])\n",
    "\n",
    "    return windows\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# define loop to decode over times and run boot strap samples over\n",
    "\n",
    "def fnc_decode_times(n_boot):\n",
    "    \"\"\"\n",
    "    Description: loop decoding over each time window\n",
    "    Returns: [acc, class, t_step]\n",
    "    \"\"\"\n",
    "    np.random.seed(n_boot)  # Ensure each bootstrap is different\n",
    "    results = []\n",
    "    for t in times:\n",
    "        seed = np.random.randint(0, 1000000)  # Unique seed for each time point within the bootstrap\n",
    "        result = fnc_fit_and_score(np.mean(data_d[:, t, :], axis=1), tri_ind, hold_out, n_cvs, afc, labs, D_params['label'], thresh, grid, seed)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# define decoding\n",
    "\n",
    "def fnc_fit_and_score(data_slice, n_cvs, labs, grid):\n",
    "    \"\"\"\n",
    "    Description: Script for decoding fitting linear SVM and scoring accuracy across CV folds\n",
    "    Fits the model on each CV fold for a given time step\n",
    "    Returns: [acc, class]\n",
    "    \"\"\"\n",
    "    acc = np.mean(cross_val_score(grid, data_slice, labs, cv = n_cvs))\n",
    "      \n",
    "    \n",
    "    return acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c1c978-d26e-4217-9ce1-e7ada7e0c412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now actually do decoding\n",
    "\n",
    "modelnum = 0 # which model do we want ranges 0 to 2?\n",
    "afc = 6\n",
    "coh = 'lo'\n",
    "fr = 1\n",
    "nboots = 10\n",
    "\n",
    "# Load data\n",
    "if sys.platform.startswith('linux'):\n",
    "    data_dir = f\"/mnt/neurocube/local/serenceslab/holly/RNN_Geo/data/rdk_{RNN_params['prob_split']}_{afc}afc/feedforward_only/{coh}_coh\"\n",
    "else:\n",
    "    data_dir = f\"/Volumes/serenceslab/holly/RNN_Geo/data/rdk_{RNN_params['prob_split']}_{afc}afc/feedforward_only/{coh}_coh\"\n",
    "mat_files = [f for f in os.listdir(data_dir) if f.endswith('.mat')]# Get all the trained models (should be 40 .mat files)\n",
    "model_path = os.path.join(data_dir, mat_files[modelnum]) \n",
    "model = loadmat(model_path)   \n",
    "data_file = f\"{data_dir}/Trials{task_info['trials']}_model{model_path[-7:-4]}_balanced.npz\"\n",
    "data = np.load(data_file)\n",
    "data_d = data[f'fr{fr}'] # this is a [trial x time step x unit] matrix\n",
    "labs = data['labs'].squeeze() # [trial x time step]\n",
    "\n",
    "# get some info about structure of the data\n",
    "tris = data_d.shape[0]             # number of trials\n",
    "tri_ind = np.arange(0,tris)      # list from 0...tris\n",
    "hold_out = int( tris / n_cvs )   # how many trials to hold out\n",
    "thresh = RNN_params.get('thresh', [.3, .7])\n",
    "\n",
    "times = fnc_sliding_window(range(task_info['stim_dur']+task_info['stim_on'],task_info['trial_dur']), window)  \n",
    "acc = np.zeros((nboots, len(times)))\n",
    "\n",
    "\n",
    "start_time = time.time() \n",
    "if __name__ == \"__main__\":\n",
    "    with Pool(processes=round(os.cpu_count() * .9)) as pool:\n",
    "        results = pool.map(fnc_decode_times, range(nboots))    \n",
    "    acc = np.array(results)\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "\n",
    "if sys.platform.startswith('linux'):\n",
    "    full_file = f'/mnt/neurocube/local/serenceslab/holly/RNN_Geo/data/decoding/fr{fr}/{coh}_{afc}afc/boot_{D_params[\"pred\"]}_all{modelnum}_garbage.npz'\n",
    "else:\n",
    "    full_file = f'/Volumes/holly/RNN_Geo/data/decoding/fr{fr}/{coh}_{afc}afc/boot_{D_params[\"pred\"]}_all{modelnum}_garbage.npz'\n",
    "\n",
    "np.savez(full_file, acc = acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e367199-1971-4a11-a899-ffd20c7df14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077b1cd8-3880-4325-a43f-19e4285b47c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
